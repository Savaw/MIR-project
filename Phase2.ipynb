{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "88a39194",
      "metadata": {
        "id": "88a39194"
      },
      "source": [
        "<center>\n",
        "\n",
        "# فاز دوم پروژه\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PCgUqTAlPxKO",
      "metadata": {
        "id": "PCgUqTAlPxKO"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "     در صورت هرگونه سوال به ایمیل‌های زیر پیام داده یا از طریق سایر پلتفرم‌ها پیگیری کنید\n",
        "    \n",
        "[Sina Tavakkoli](mailto:stavakkoli1999@gmail.com)\n",
        "     <br>\n",
        "[Alireza Daqiq](mailto:alireza.daghigh1999@gmail.com)\n",
        "    \n",
        " </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "657af262",
      "metadata": {
        "id": "657af262"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "## I. خلاصه انجام پروژه\n",
        "\n",
        "در این تمرین, می‌خواهیم یک تصحیح‌کننده‌ی غلط‌املایی احتمالاتی بسازیم که غلط‌های موجود در کوئری را اصلاح کند.\n",
        "   ورودی ما در این مسئله, کوئری $R$ است و هدف پیدا کردن کوئری درست $Q$ است که احتمال $P(Q\\mid R)$ را بیشینه کند. \n",
        "    بر اساس قضیه‌ی بیز داریم :\n",
        "    \n",
        "$$\n",
        "    P(Q\\mid R) = \\frac{P(R\\mid Q)P(Q)}{P(R)}\\propto P(R\\mid Q)P(Q).\n",
        "$$\n",
        "    \n",
        "از آنجایی که هدف ما پیدا کردن $Q$یی است که عبارت $P(Q\\mid R)$ را بیشینه کند, تنها کافی‌ست که $P(R\\mid Q)P(Q)$ را بیشینه کنیم.\n",
        "    حال با توجه به چیزهایی که گفته شد, مصحح غلط‌املایی احتمالاتی ما باید چهار بخش داشته باشد:\n",
        "  1.  **مدل ‌زبانی.**(Language Model) \\\n",
        "      توزیع اولیه‌ی یونیگرام‌ها و بایگرام‌ها را حساب می‌کند. این کار به ما اجازه می‌دهد که $P(Q)$ حساب کنیم. ما از maximum-likelihood estimation استفاده می‌کنیم, که وقوع توکن یونیگرام و بایگرام‌ها را در training corpus برای تعیین کردن احتمالات اولیه می‌شمرد.\n",
        "  2. **مدل احتمال ویرایش.** (Edit Probability Model)\\\n",
        "      احتمال خطاهایی که ممکن است در یک کوئری اتفاق بیافتد را حساب می‌کند. این به ما اجازه می‌دهد که $P(R\\mid Q)$ را محاسبه کنیم. به طور خاص، این کامپوننت احتمال کرکترهایی را حساب می‌کند که در یک کوئری ترم به اشتباه حذف، درج، جایگزین یا ترنسپوز شده‌اند.\n",
        "  3. **تولیدکننده‌ی نامزدها.** (Candidate Generator)\\\n",
        "      کوئری خام $R$ که توسط کاربر ثبت شده است را می‌گیرد و نامزد‌های $Q$ را تولید می‌کند.\n",
        "  4. **امتیازدهنده‌ی نامزدها.** (Candidate Scorer)\\\n",
        "      موارد (1), (2) و (3) را برای محاسبه‌ی $Q^{*} = \\arg\\max_{Q}P(Q\\mid R)$ ترکیب می‌کند. یعنی برای هر $Q$ که توسط تولید‌کننده‌ی نامزدها تولید شده است، امتیازدهنده از مدل‌زبان برای محاسبه‌ی $P(Q)$ و از مدل احتمال ویرایش برای محاسبه‌ی $P(R\\mid Q)$ استفاده می‌کند و در نهایت $Q$ را انتخاب می‌کند که مقدار $P(Q)P(R\\mid Q)$ بیشینه می‌کند.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z3TkKKFXQSx6",
      "metadata": {
        "id": "Z3TkKKFXQSx6"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "## II. جزئیات پروژه\n",
        "\n",
        "\n",
        "  1. [تسک اول: تصحیح املا با استفاده از Uniform Edit Costs](#uniform)\n",
        "  2. [تسک دوم: تصحیح املا با استفاده از Empirical Edit Costs](#empirical)\n",
        "  3. [گزارش مکتوب](#written)\n",
        "    </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb003c31",
      "metadata": {
        "id": "fb003c31"
      },
      "source": [
        "<a id=\"dataset\"></a>\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "## III. دیتاست\n",
        "\n",
        "\n",
        "برای این تمرین, ما برای داده‌های تمرین و تست  از یکی از دیتا‌ست‌های دانشگاه استنفورد با اندکی تغییرات استفاده کردیم\n",
        "برای متون هم ازیکی از آزمایشگاه‌های این دانشگاه بهره بردیم.\n",
        "\n",
        "   <div dir=\"rtl\">\n",
        "   دیتاست از این <a href=\"https://drive.google.com/file/d/17ukKiVAYtbBuL_zI8_2IhZ8uzxkMJdPs/view?usp=sharing\"> لینک </a> قابل دسترسی است. آن‌را دانلود کرده و کنار notebook قرار دهید و سلول زیر را اجرا کنید . دیتاست شامل سه بخش زیر است:\n",
        "    </div>\n",
        "    <ul>\n",
        "       <li>  corpusها : در پوشه مربوط به آن ۱۰ فایل می‌بینید که هر خط هر فایل از یک مستند است. از tokenهای این بخش در ساخت model استفاده کنید</li>\n",
        "       <li> training set: شامل جفت‌هایی از عبارات غلط و درست‌ آنها که با حداکثر یک عدد که edit distanceآنهاست جدا شده‌اند</li>\n",
        "       <li>  dev set : در پوشه مربوطه سه فایل وجود دارد, ورژن عبارات با غلط املایی, ورژن صحیح آنها در gold.txt  و ورژن تصحیح شده توسط google در google.txt </li>\n",
        "    </ul>    \n",
        "    </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YA8xKmjDn06Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA8xKmjDn06Q",
        "outputId": "103c9855-5170-40f1-b0b1-8b9a657a22bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17ukKiVAYtbBuL_zI8_2IhZ8uzxkMJdPs\n",
            "To: /content/MIR2-data.zip\n",
            "100% 46.6M/46.6M [00:00<00:00, 65.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 17ukKiVAYtbBuL_zI8_2IhZ8uzxkMJdPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MUDivuMIn7VM",
      "metadata": {
        "id": "MUDivuMIn7VM"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zf = zipfile.ZipFile(\"/content/MIR2-data.zip\")\n",
        "zf.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e02cc2ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e02cc2ac",
        "outputId": "436c6099-d79e-4721-8bde-9e1bb90c2fdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# google_colab = True\n",
        "# google_colab_path_to_data_dir = 'Uni/MIR'\n",
        "\n",
        "# base_dir = ''\n",
        "# if google_colab:\n",
        "#   from google.colab import drive\n",
        "\n",
        "#   drive.mount('/content/drive')\n",
        "#   base_dir = f\"/content/drive/MyDrive/{google_colab_path_to_data_dir}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64022bd",
      "metadata": {
        "id": "e64022bd"
      },
      "outputs": [],
      "source": [
        "# Import modules\n",
        "import math\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from itertools import chain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0L-1l8eMPxKa",
      "metadata": {
        "id": "0L-1l8eMPxKa"
      },
      "source": [
        "<div dir='rtl'>\n",
        "در تغییر ساختار کد در هر بخش آزاد هستید, فقط خروجی‌ها باید مورد انتظار بوده و تغییر داده شده در گزارش مکتوب آورده شود\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "764617ad",
      "metadata": {
        "id": "764617ad"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<a id='uniform'></a>\n",
        "## IV. تسک اول:\n",
        "\n",
        "### IV.1. مدل‌زبان\n",
        "\n",
        "  حال می‌خواهیم یک مدل‌زبان برا پیشبینی $P(Q)$ از training corpusها بسازیم. رفتار ما با $P(Q)$ به صورت مجموعه‌ای از ترم‌های $(w_1, \\ldots, w_n)$ است که:\n",
        "\n",
        "  $$\n",
        "P(w_1, \\ldots, w_n) = P(w_1)P(w_2\\mid w_1)\\cdots P(w_n\\mid w_{n-1}),\n",
        "$$\n",
        "\n",
        "  که $P(w_1)$ در واقع احتمال یونیگرام ترم$w_1$  و $P(w_{i}\\mid w_{i-1})$ و احتمال بایگرام $(w_{i-1}, w_i)$ برای $i \\in \\{2, \\ldots, n\\}$ است.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc7e86e",
      "metadata": {
        "id": "6cc7e86e"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "مدل‌زبان برای به دست آوردن احتمالات از MLE استفاده می کند:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "  P_{\\text{MLE}}(w_i) & = \\frac{\\texttt{count}(w_i)}{T},\n",
        "  &\n",
        "  P_{\\text{MLE}}(w_i\\mid w_{i-1}) & = \\frac{\\texttt{count}((w_{i}, w_{i-1}))}{\\texttt{count}(w_{i-1})},\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "که $T$ تعداد کل توکن‌ها در corpus است و $\\texttt{count}$ تعداد یونیگرام‌ها و بایگرام‌هاست.\n",
        "\n",
        "برای به‌دست آوردن count برای یونیگرام‌ها و بایگرام‌ها در corpus، کد زیر را کامل کنید:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e19b1385",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e19b1385",
        "outputId": "ce6d882e-242c-4e80-e38e-f956746f0329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing 2.txt...\n",
            "processing 6.txt...\n",
            "processing 1.txt...\n",
            "processing 0.txt...\n",
            "processing 9.txt...\n",
            "processing 7.txt...\n",
            "processing 5.txt...\n",
            "processing 3.txt...\n",
            "processing 8.txt...\n",
            "processing 4.txt...\n"
          ]
        }
      ],
      "source": [
        "class LanguageModel:\n",
        "    \"\"\"Models prior probability of unigrams and bigrams.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus_dir='MIR2-data/corpus', lambda_=0.1):\n",
        "        \"\"\"Iterates over all whitespace-separated tokens in each file in\n",
        "        `corpus_dir`, and counts the number of occurrences of each unigram and\n",
        "        bigram. Also keeps track of the total number of tokens in the corpus.\n",
        "\n",
        "        Args:\n",
        "            corpus_dir (str): Path to directory containing corpus.\n",
        "            lambda_ (float): Interpolation factor for smoothing by unigram-bigram\n",
        "                interpolation. You only need to save `lambda_` as an attribute for now, and\n",
        "                it will be used later in `LanguageModel.get_bigram_logp`. See Section\n",
        "                IV.1.2. below for further explanation.\n",
        "        \"\"\"\n",
        "        self.lambda_ = lambda_\n",
        "        self.total_num_tokens = 0        # Counts total number of tokens in the corpus\n",
        "        self.unigram_counts = Counter()  # Maps strings w_1 -> count(w_1)\n",
        "        self.bigram_counts = Counter()   # Maps tuples (w_1, w_2) -> count((w_1, w_2))\n",
        "\n",
        "        ### Begin your code\n",
        "\n",
        "        for file in os.listdir(corpus_dir):\n",
        "          print(f\"processing {file}...\")\n",
        "          with open(corpus_dir + os.path.sep + file ) as f:\n",
        "              lines = f.read().splitlines()\n",
        "  \n",
        "              # words_chain = chain.from_iterable(map(str.split, f))\n",
        "              # words_list = list(words_chain)\n",
        "              words_list = list(chain.from_iterable(line.lower().split() for line in lines))\n",
        "\n",
        "              c1 = Counter(words_list)\n",
        "              self.unigram_counts += c1\n",
        "\n",
        "              bigrams = [i for j in lines \n",
        "                        for i in zip(j.split(\" \")[:-1], j.split(\" \")[1:])]\n",
        "              c2 = Counter(bigrams)\n",
        "              self.bigram_counts += c2\n",
        "\n",
        "              self.total_num_tokens += len(words_list)\n",
        "        \n",
        "\n",
        "        # print(\"total_num_tokens:\", self.total_num_tokens)\n",
        "        # print(\"unigrams count:\", len(self.unigram_counts.items()))\n",
        "        # print(\"bigrams count:\", len(self.bigram_counts.items()))\n",
        "\n",
        "        ### End your code\n",
        "\n",
        "lm = LanguageModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dd00ef9",
      "metadata": {
        "id": "9dd00ef9"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "   حال که تعداد یونیگرام‌ها و بایگرام‌ها را محاسبه کردیم، باید احتمال کوئری‌ها را نیز بسنجیم. قبل از ان به بایگرام‌هایی بپردازیم که هیچ‌گاه در corpus ندیدیم.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4bbe094",
      "metadata": {
        "id": "a4bbe094"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "#### IV.1.2.  هموارسازی با استفاده از درون‌یابی ( Smoothing by Interpolation)\n",
        "\n",
        "مدل احتمال یونیگرام به عنوان مجموعه لغات ما هم خواهد بود. چون فرض می‌کنیم که کوئری ما از مستند corpus آمده است، درنتیجه در احتمالات یونیگرام خود نیازی به [هموارسازی لاپلاس](https://en.wikipedia.org/wiki/Additive_smoothing) نداریم، چون نامزدهای ما از همین لغت‌نامه آمده‌اند. اما حتی اگر دو کوئری ترم داشتیم که هردوی آن‌ها جزو کوئری زبان ما بودند، تضمینی نیست که بایگرام متناظر آن‌ها در training corpus وجود داشته باشند. برای مدیریت این پراکندگی داده ما احتمالات یونیگرام و بایگرام را برای به دست آوردن احتمال شرطی نهایی خود *درون‌یابی* می‌کنیم:\n",
        "$$\n",
        "P(w_2\\mid w_1) = \\lambda P_{\\text{MLE}}(w_2) + (1 - \\lambda)P_{\\text{MLE}}(w_2\\mid w_1).\n",
        "$$\n",
        "با قرار دادن یک مقدار کوچک به جای $\\lambda$ (برای مثال، 0.1) شروع می‌کنیم و سپس با تغییر این متغیر آزمون و خطا می‌کنیم تا دقت تصحیح ما در دیتاست توسعه بالاتر برود. توجه کنید که در این مورد برای دیتاست مورد نظر overﬁt نکنید. می‌توانید یک قسمت کوچک از داده‌های خود را برای tune کردن پارامترها نگه‌دارید.\n",
        "\n",
        "توابع زیر را برای کامل کردن کلاس `LanguageModel` بنویسید."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b92a780e",
      "metadata": {
        "id": "b92a780e"
      },
      "outputs": [],
      "source": [
        "# NOTE: Syntax on the following line just extends the `LanguageModel` class\n",
        "class LanguageModel(LanguageModel):\n",
        "    def get_unigram_count_log(self, unigram):\n",
        "        if self.unigram_counts[unigram] == 0:\n",
        "          return 0\n",
        "\n",
        "        return math.log(self.unigram_counts[unigram])\n",
        "\n",
        "    def get_bigram_count_log(self, bigram):\n",
        "        if self.bigram_counts[bigram] == 0:\n",
        "          return 0\n",
        "\n",
        "        return math.log(self.bigram_counts[bigram])\n",
        "\n",
        "\n",
        "    def get_unigram_logp(self, unigram):\n",
        "        \"\"\"Computes the log-probability of `unigram` under this `LanguageModel`.\n",
        "\n",
        "        Args:\n",
        "            unigram (str): Unigram for which to compute the log-probability.\n",
        "\n",
        "        Returns:\n",
        "            log_p (float): Log-probability of `unigram` under this\n",
        "                `LanguageModel`.\n",
        "        \"\"\"\n",
        "        ### Begin your code\n",
        "        \n",
        "        return self.get_unigram_count_log(unigram) - math.log(self.total_num_tokens)\n",
        "        \n",
        "        ### End your code\n",
        "\n",
        "    def get_bigram_logp(self, w_1, w_2):\n",
        "        \"\"\"Computes the log-probability of `unigram` under this `LanguageModel`.\n",
        "\n",
        "        Note:\n",
        "            Use self.lambda_ for the unigram-bigram interpolation factor.\n",
        "\n",
        "        Args:\n",
        "            w_1 (str): First word in bigram.\n",
        "            w_2 (str): Second word in bigram.\n",
        "\n",
        "        Returns:\n",
        "            log_p (float): Log-probability of `bigram` under this\n",
        "                `LanguageModel`.\n",
        "        \"\"\"\n",
        "        ### Begin your code\n",
        "\n",
        "        p_mle_w2 = self.get_unigram_logp(w_2)\n",
        "        p_mle_w1_w2 = self.get_bigram_count_log((w_1, w_2)) - self.get_unigram_count_log(w_1)\n",
        "\n",
        "        return math.log(self.lambda_) + p_mle_w2 - math.log(1 - self.lambda_) - p_mle_w1_w2\n",
        "\n",
        "        ### End your code\n",
        "\n",
        "    def get_query_logp(self, query):\n",
        "        \"\"\"Computes the log-probability of `query` under this `LanguageModel`.\n",
        "\n",
        "        Args:\n",
        "            query (str): Whitespace-delimited sequence of terms in the query.\n",
        "\n",
        "        Returns:\n",
        "            log_p (float): Log-probability assigned to the query under this\n",
        "                `LanguageModel`.\n",
        "        \"\"\"\n",
        "        ### Begin your code\n",
        "\n",
        "        words = query.split()\n",
        "\n",
        "        p = self.get_unigram_logp(words[0])\n",
        "\n",
        "        for i in range(len(words) - 1):\n",
        "            p += self.get_bigram_logp(words[i], words[i+1])\n",
        "\n",
        "        return p\n",
        "        ### End your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273c3491",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "273c3491",
        "outputId": "962565f7-20a0-4295-b798-e6e2d43be04c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing 2.txt...\n",
            "processing 6.txt...\n",
            "processing 1.txt...\n",
            "processing 0.txt...\n",
            "processing 9.txt...\n",
            "processing 7.txt...\n",
            "processing 5.txt...\n",
            "processing 3.txt...\n",
            "processing 8.txt...\n",
            "processing 4.txt...\n",
            "num. unigrams(\"347071\")\n",
            "num. bigrams(\"4455519\")\n",
            "num. tokens(\"25498340\")\n",
            "P(\"sharif university\") == 9.174135574067575e-10\n",
            "P(\"sharaf universit\") == 5.810487778026424e-15\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# Make sure your implementation passes the following sanity checks\n",
        "# Note: Constructing the language model could take 30 seconds or longer\n",
        "# We suggest using `tqdm` to track progress in your `LanguageModel.__init__` function.\n",
        "lm = LanguageModel()\n",
        "\n",
        "print('num. unigrams(\"{}\")'.format(len(lm.unigram_counts))) \n",
        "print('num. bigrams(\"{}\")'.format(len(lm.bigram_counts)))\n",
        "print('num. tokens(\"{}\")'.format(lm.total_num_tokens))\n",
        "\n",
        "\n",
        "# Test a reasonable query with and without typos (you should try your own)!\n",
        "query_wo_typo = \"sharif university\" # write a query without typo\n",
        "query_w_typo = \"sharaf universit\"  # write a query with typo\n",
        "\n",
        "p_wo_typo = math.exp(lm.get_query_logp(query_wo_typo))\n",
        "p_w_typo = math.exp(lm.get_query_logp(query_w_typo))\n",
        "print('P(\"{}\") == {}'.format(query_wo_typo, p_wo_typo))\n",
        "print('P(\"{}\") == {}'.format(query_w_typo, p_w_typo))\n",
        "if p_wo_typo <= p_w_typo:\n",
        "    print('Are you sure \"{}\" should be assigned higher probability than \"{}\"?'\n",
        "          .format(query_w_typo, query_wo_typo))\n",
        "    \n",
        "print(\"done!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cbed225",
      "metadata": {
        "id": "4cbed225"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "### IV.2.  مدل احتمال ویرایش (Edit Probability Model)\n",
        "\n",
        "مدل احتمال ویرایش تلاش می‌کند تا مقدار $P(R\\mid Q)$ را محاسبه کند. برای یک کوئری نامزد ثابت $Q$، مدل احتمال ویرایش احتمالی را حساب می‌کند که یک کوئری خام احتمالا خطادار $R$ ثبت شده است. در این‌جا فاصله‌ی بین کوئری نامزد $Q$ و ورودی $R$ را با استفاده از [فاصله‌ی Damerau-Levenshtein](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance) مقداردهی می‌کنیم. در فاصله‌ی Damerau-Levenshtein، ویرایش‌های احتمالی برابرthe possible edits are **درج**، **حذف**، **جایگزینی** و **جابجایی**، که هرکدام شامل تک‌کرکترها به عنوان عملگر هستند. در پایین یک کلاس پایه برای `EditCostModel` را می‌بینید."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "786b119e",
      "metadata": {
        "id": "786b119e"
      },
      "outputs": [],
      "source": [
        "\n",
        "class BaseEditProbabilityModel:\n",
        "    def get_edit_logp(self, edited, original):\n",
        "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
        "        The `original` and `edited` arguments are both single terms that are at\n",
        "        most one edit apart.\n",
        "        \n",
        "        Note: The order of the arguments is chosen so that it reads like an\n",
        "        assignment expression:\n",
        "            > edited := EDIT_FUNCTION(original)\n",
        "        or, alternatively, you can think of it as a (unnormalized) conditional probability:\n",
        "            > log P(edited | original)\n",
        "\n",
        "        Args:\n",
        "            edited (str): Edited term.\n",
        "            original (str): Original term.\n",
        "\n",
        "        Returns:\n",
        "            logp (float): Log-probability of `edited` given `original`\n",
        "                under this `EditProbabilityModel`.\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b31bbaba",
      "metadata": {
        "id": "b31bbaba"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "**نکته مهمی که باید بدانیم این‌است که تابع get_edit_logp با دو ورودی صدا زده می شود که edit-distance آنها یک است.** \n",
        "<br>همچنین خروجی نیازی به نرمال شدن ندارد که مجموع احتمالات کانید‌ها یک شود.\n",
        "\n",
        "</div>\n",
        "\n",
        "```python\n",
        "epm = EditProbabilityModelSubclass(...)  # You will define such a subclass later\n",
        "original = 'user'\n",
        "edited = 'usre'                      # Edited by transposing 'r' and 'e'\n",
        "score = epm.get_edit_logp(edited, original)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46dd0c23",
      "metadata": {
        "id": "46dd0c23"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "#### IV.2.1. مدل ویرایش Uniform-Cost\n",
        "\n",
        "ابتدا *uniform-cost edit model* را پیاده‌سازی می‌کنیم. این مدل محاسبه‌ی احتمال ویرایش را با فرض این که هر ویرایش در فاصله‌ی Damerau-Levenshtein احتمال یکسان دارد، ساده می‌کند. شما باید یک بازه از مقادیر را برای احتمال ویرایش uniform امتحان کنید، اما برای شروع، بازه‌ی 0.01 - 0.10 مناسب است. یک نکته‌ی مهم که باید در ساختن مدل خود به خاطر داشته باشید، این است که کوئری ورودی $R$ کاربر در اکثر مواقع صحیح است (*برای مثال،* $R = Q$). بنابراین باید یک احتمال ثابت بالا برای `edited == original` در نظر گرفته شود؛یک بازه‌ی معقول 0.90 - 0.95 است.\n",
        "\n",
        "مدل احتمال ویرایشی که در اینجا می‌سازید، زمانی که نامزدهای تصحیح کوئری را رتبه‌بندی می‌کنید استفاده خواهد شد. تولیدکننده‌ی این نامزدها (که در بخش بعدی توضیح داده شده‌ است) یک ویرایش در هر زمان انجام می‌دهد و هر وقت یک ویرایش در یک ترم انجام می‌دهد، مدل احتمال ویرایش را صدا می‌زند و log-probabilities را برای تغییرات multi-edit جمع می‌کند. بنابراین در این قسمت شما تنها باید احتمال `edited` را با توجه به این که این مورد **حداکثر یک ویرایش تا `original` فاصله دارد** حساب کنید. یعنی در اینجا `get_edit_logp` خیلی ساده خواهد بود.\n",
        "\n",
        "برای پیاده‌سازی مدل ویرایش uniform-cost کلاس زیر را کامل کنید."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef111c1",
      "metadata": {
        "id": "eef111c1"
      },
      "outputs": [],
      "source": [
        "\n",
        "class UniformEditProbabilityModel(BaseEditProbabilityModel):\n",
        "    def __init__(self, edit_prob=0.05):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            edit_prob (float): Probability of a single edit occurring, where\n",
        "                an edit is an insertion, deletion, substitution, or transposition,\n",
        "                as defined by the Damerau-Levenshtein distance.\n",
        "        \"\"\"\n",
        "        self.edit_prob = edit_prob\n",
        "\n",
        "    def get_edit_logp(self, edited, original):\n",
        "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
        "        The `original` and `edited` arguments are both single terms that are at\n",
        "        most one edit apart.\n",
        "        \n",
        "        Note: The order of the arguments is chosen so that it reads like an\n",
        "        assignment expression:\n",
        "            > edited := EDIT_FUNCTION(original)\n",
        "        or, alternatively, you can think of it as a (unnormalized) conditional probability:\n",
        "            > log P(edited | original)\n",
        "\n",
        "        Args:\n",
        "            edited (str): Edited term.\n",
        "            original (str): Original term.\n",
        "\n",
        "        Returns:\n",
        "            logp (float): Log-probability of `edited` given `original`\n",
        "                under this `EditProbabilityModel`.\n",
        "        \"\"\"\n",
        "        ### Begin your code\n",
        "\n",
        "        dist = [[None for i in range(len(original)+1)] for j in range(len(edited)+1)]\n",
        "        for i in range(0, len(edited)+1):\n",
        "          for j in range(0, len(original)+1):\n",
        "            if i == 0:\n",
        "              dist[i][j] = j\n",
        "            elif j == 0:\n",
        "              dist[i][j] = i\n",
        "            else:\n",
        "              dist[i][j] = min(dist[i-1][j] + 1, \n",
        "                               dist[i][j-1] + 1, \n",
        "                               dist[i-1][j-1] + (0 if edited[i-1] == original[j-1] else 1))\n",
        "              \n",
        "              if i - 2 >= 0 and j - 2 >= 0 and \\\n",
        "                edited[i-1] == original[j-2] and edited[i-2] == original[j-1]:\n",
        "                dist[i][j] = min(dist[i][j], dist[i-2][j-2] + 1)\n",
        "            \n",
        "        if dist[len(edited)][len(original)] == 0:\n",
        "          return math.log(1 - self.edit_prob)\n",
        "        elif dist[len(edited)][len(original)] == 1:\n",
        "          return math.log(self.edit_prob)\n",
        "        else:\n",
        "          return 0\n",
        "\n",
        "\n",
        "    def get_query_edit_logp(self, edited, original):\n",
        "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
        "        The `original` and `edited` arguments are both queries with same number \n",
        "        of terms.\n",
        "\n",
        "        Args:\n",
        "            edited (str): Edited query.\n",
        "            original (str): Original query.\n",
        "\n",
        "        Returns:\n",
        "            logp (float): Log-probability of `edited` given `original`\n",
        "                under this `EditProbabilityModel`.\n",
        "        \"\"\"\n",
        "        ### Begin your code\n",
        "\n",
        "        p = 0\n",
        "        for term1, term2 in zip(edited, original):\n",
        "          p += self.get_edit_logp(term1, term2)\n",
        "\n",
        "        return p\n",
        "        ### End your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b3a180c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b3a180c",
        "outputId": "ba0f75f8-9bcc-46c9-fb77-12f10fa3796f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "EDIT_PROB = 0.05\n",
        "epm = UniformEditProbabilityModel(edit_prob=EDIT_PROB)\n",
        "\n",
        "# Test a basic edit\n",
        "edited, original = 'usre', 'user'\n",
        "print(math.isclose(epm.get_edit_logp(edited, original), math.log(EDIT_PROB)))\n",
        "\n",
        "# Test a non-edit\n",
        "print( math.isclose(epm.get_edit_logp(original, original), math.log(1. - EDIT_PROB)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3d3802a",
      "metadata": {
        "id": "b3d3802a"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "### IV.3. تولیدکننده‌ی نامزدها \n",
        "\n",
        "تولیدکننده‌ی نامزدها یک کوئری خام $R$ که توسط کاربر ثبت شده است را می‌گیرد و برای کوئری مورد نظر $Q$ نامزدها را تولید می‌کند. از آن‌جایی که می‌دانیم بیشتر از 97% خطاهای املایی در یک فاصله ویرایش ۲ از کوئری موردنظر کاربر قرار دارند، پیشنهاد می‌شود اصلاح کوئری‌های موجود در این فاصله را از $R$ در نظر بگیرید. این راه‌حلی است که توسط Peter Norvig در [این مقاله در مورد اصلاح خطاهای املایی](http://norvig.com/spell-correct.html) پیشنهاد شده است. اگرچه استفاده از یک تولیدکننده‌ی بروت فورس خالص که تمام رشته‌های ممکن با فاصله‌ی ۲ از  $R$ را تولید کند راه معقولی نیست، چون برای هر $R$ با طول غیرناچیز، تعداد نامزدها خیلی زیاد خواهد شد. بنابراین ما باید مدل احتمال زبان و ویرایش را برای تعداد زیادی از نامزدها محاسبه کنیم.\n",
        "\n",
        "#### IV.3.1. تولیدکننده‌ی نامزدها با فضای جستجوی محدود (Candidate Generator with Restricted Search Space)\n",
        "\n",
        "ما می‌توانیم راه‌حل ساده‌ای را پیش بگیریم که با محدود کردن زیاد فضای جستجو در حین تولید کردن نامزدها قابل مدیریت است. راه‌حل‌های معتبر زیادی برای تولید نامزد بهینه وجود دارد، چند ایده‌ی ساده در زیر آمده:\n",
        "  - با بررسی *هر ترم، جداگانه* در رشته کوئری $R$ شروع کنید و تمام ویرایش‌های ممکن که با فاصله ۱ از آن‌ ترم وجود دارند را در نظر بگیرید.\n",
        "  - به یاد داشته باشید که می‌توانید هایفن‌ها (علامت خط تیره) یا اسپیس‌ها را به عنوان عناصر مجموعه‌ی کرکترهای خود در نظر بگیرید. با این کار می‌توانید تعدادی خطای نسبتا رایج را در نظر بگیرید، برای مثال وقتی در میان یک کلمه به اشتباه فاصله می‌افتد یا زمانی که دو ترم در یک کوئری به اشتباه توسط اسپیس جدا می‌شوند و در واقع باید به هم چسبیده باشند.\n",
        "  - هر وقت برای یک ترم ویرایشی را اعمال می‌کنید، مطمئن شوید که ترم ویرایش شده در دیکشنری ظاهر شود. (به خاطر داشته باشید که فرض کردیم تمام لغات در یک کوئری نامزد معتبر در training corpus ما قابل یافت است).\n",
        "  - اگر ویرایش‌های ممکن برای چندترم جدا را تولید کردید، محصول کارتزین این ترم‌ها را برای تولید یک کوئری نامزد کامل که شامل ویرایش‌های چندین ترم است را در نظر بگیرید. (اما فراموش نکنید که فاصله ویرایش شما برای کل کوئری جمعا نباید از ۲ بیشتر شود).\n",
        "  \n",
        "استراتژی‌های ذکر شده در بالا فقط در حد ایده‌ی اولیه‌ هستند و می‌توانند تا مقدار زیادی گسترش یابند یا تغییر کنند. پیشنهاد می‌کنیم چند گزینه‌ی مختلف را بررسی کنید و در گزارش کتبی خود استراتژی نهایی خود را ذکر کنید و این که چگونه کاربری این استراتژی را به مقدار بهینه رساندید. در نظر داشته باشید که **راه‌حل‌هایی که تمام کوئری‌های نامزد در فاصله‌ی مورد نظر را تولید می‌کنند بسیار کند هستند و نمره‌ی کامل نخواهند داشت.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8056cf7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8056cf7a",
        "outputId": "bd3b3ff9-c63e-4f0f-b163-54dd5a9d4161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data unzipped to /content/drive/MyDrive/Uni/MIR/MIR2-data...\n",
            "\n",
            "Directory Structure:\n",
            "/content/drive/MyDrive/Uni/MIR/MIR2-data/\n",
            "  - corpus/\n",
            "  - dev_set/\n",
            "  - training_set/\n"
          ]
        }
      ],
      "source": [
        "# Download dataset\n",
        "# go to this url and download dataset https://drive.google.com/file/d/17ukKiVAYtbBuL_zI8_2IhZ8uzxkMJdPs/view?usp=sharing\n",
        "data_dir = f'{base_dir}/MIR2-data'\n",
        "\n",
        "# Unzip dataset\n",
        "with zipfile.ZipFile('{}.zip'.format(data_dir), 'r') as zip_fh:\n",
        "    zip_fh.extractall()\n",
        "print('Data unzipped to {}...\\n'.format(data_dir))\n",
        "\n",
        "# Print the directory structure\n",
        "print('Directory Structure:')\n",
        "print(data_dir + os.path.sep)\n",
        "for sub_dir in os.listdir(data_dir):\n",
        "    if not sub_dir.startswith('.'):\n",
        "        print('  - ' + sub_dir + os.path.sep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557738fe",
      "metadata": {
        "id": "557738fe"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CandidateGenerator:\n",
        "    # Alphabet to use for insertion and substitution\n",
        "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "                'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
        "                '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                ' ', ',', '.', '-']\n",
        "\n",
        "    def __init__(self, lm, epm):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            lm (LanguageModel): Language model to use for prior probabilities, P(Q).\n",
        "            epm (EditProbabilityModel): Edit probability model to use for P(R|Q).\n",
        "        \"\"\"\n",
        "        self.lm = lm\n",
        "        self.epm = epm\n",
        "\n",
        "    def get_num_oov(self, query):\n",
        "        \"\"\"Get the number of out-of-vocabulary (OOV) words in `query`.\"\"\"\n",
        "        return sum(1 for w in query.strip().split()\n",
        "                   if w not in self.lm.unigram_counts)\n",
        "\n",
        "    def filter_and_yield(self, query, lp):\n",
        "        if query.strip() and self.get_num_oov(query) == 0:\n",
        "            yield query, lp\n",
        "\n",
        "    def get_candidates(self, query):\n",
        "        \"\"\"Starts from `query`, and performs EDITS OF DISTANCE <=2 to get new\n",
        "        candidate queries. To make scoring tractable, only returns/yields\n",
        "        candidates that satisfy certain criteria (ideas for such criteria are\n",
        "        described in bullet points above).\n",
        "\n",
        "        Hint: We suggest you implement a helper function that takes a term and\n",
        "            generates all possible edits of distance one from that term.\n",
        "            It should probably only return edits that are in the vocabulary\n",
        "            (i.e., edits for which `self.get_num_oov(edited) == 0`).\n",
        "\n",
        "        Args:\n",
        "            query (str): Starting query.\n",
        "\n",
        "        Returns:\n",
        "            Iterable over tuples (cdt, cdt_edit_logp) of candidates and\n",
        "                their associated edit log-probabilities. Return value could be\n",
        "                a list or a generator yielding tuples of this form.\n",
        "        \"\"\"\n",
        "        # Yield the unedited query first\n",
        "        # We provide this line as an example of how to use `self.filter_and_yield`\n",
        "        # yield from self.filter_and_yield(query, self.epm.get_edit_logp(query, query))\n",
        "\n",
        "        ### Begin your code\n",
        "        query_splitted = query.split()\n",
        "        suggested_terms = []\n",
        "\n",
        "        #one word dif\n",
        "        for i in range(0, len(query_splitted)):\n",
        "          possible_term_i = self.get_distance_one_terms(query_splitted[i])\n",
        "          suggested_terms.append(possible_term_i)\n",
        "          for possible_term in possible_term_i:\n",
        "            new_query_terms = [*query_splitted[:i], possible_term, *query_splitted[i+1:]]\n",
        "            new_query = \" \".join(new_query_terms)\n",
        "            yield from self.filter_and_yield(new_query, self.epm.get_query_edit_logp(new_query, query))\n",
        "\n",
        "        # two word dif\n",
        "        for i in range(0, len(query_splitted) - 1):\n",
        "          for j in range(1, len(query_splitted)):\n",
        "            for suggested_term_i in suggested_terms[i]:\n",
        "              for suggested_term_j in suggested_terms[j]:\n",
        "                new_query_terms = [*query_splitted[:i], suggested_term_i, *query_splitted[i+1:j], suggested_term_j, *query_splitted[j+1:]]\n",
        "                new_query = \" \".join(new_query_terms)\n",
        "                yield from self.filter_and_yield(new_query, self.epm.get_query_edit_logp(new_query, query))\n",
        "\n",
        "        #join two words\n",
        "        for i in range(0, len(query_splitted) - 1):\n",
        "          joined_word = query_splitted[i] + query_splitted[i+1]\n",
        "          if joined_word in self.lm.unigram_counts:\n",
        "            new_query_terms = [*query_splitted[:i], joined_word, *query_splitted[i+1:]]\n",
        "            new_query = \" \".join(new_query_terms)\n",
        "            yield from self.filter_and_yield(new_query, self.epm.get_query_edit_logp(new_query, query))\n",
        "\n",
        "        ### End your code\n",
        "    \n",
        "    def get_distance_one_terms(self, term):\n",
        "\n",
        "      possible_words = {term}\n",
        "\n",
        "      #deletion\n",
        "      for i in range(0,len(term)):\n",
        "        new_term = term[:i]+term[i+1:]\n",
        "        #hyphen\n",
        "        if term[i] == \"-\":\n",
        "          new_term_1 = term[:i]\n",
        "          new_term_2 = term[i+1:]\n",
        "          if new_term_1 in self.lm.unigram_counts and new_term_2 in self.lm.unigram_counts:\n",
        "            possible_words.add(new_term)\n",
        "        #non-hyphen\n",
        "        else:\n",
        "          if new_term in self.lm.unigram_counts:\n",
        "            possible_words.add(new_term)\n",
        "      \n",
        "      #insertion\n",
        "      for i in range(0,len(term) + 1):\n",
        "        for j in range(0, len(self.alphabet)):\n",
        "          new_term = term[:i] + self.alphabet[j] + term[i:]\n",
        "          #space\n",
        "          if self.alphabet[j] == \" \":\n",
        "            new_term_1 = term[:i]\n",
        "            new_term_2 = term[i:]\n",
        "            if new_term_1 in self.lm.unigram_counts and new_term_2 in self.lm.unigram_counts:\n",
        "              possible_words.add(new_term)\n",
        "          #non_space\n",
        "          else:\n",
        "            if new_term in self.lm.unigram_counts:\n",
        "              possible_words.add(new_term)\n",
        "\n",
        "      #substitution\n",
        "      for i in range(0, len(term)):\n",
        "        for j in range(0, len(self.alphabet)):\n",
        "          if(term[i] != self.alphabet[j]):\n",
        "            new_term = term[:i] + self.alphabet[j] + term[i+1:]\n",
        "            #space\n",
        "            if self.alphabet[j] == \" \":\n",
        "              new_term_1 = term[:i]\n",
        "              new_term_2 = term[i+1:]\n",
        "              if new_term_1 in self.lm.unigram_counts and new_term_2 in self.lm.unigram_counts:\n",
        "                possible_words.add(new_term)\n",
        "            #non_space\n",
        "            else:\n",
        "              if new_term in self.lm.unigram_counts:\n",
        "                possible_words.add(new_term)\n",
        "\n",
        "      #tranposition\n",
        "      for i in range(0, len(term) - 1):\n",
        "        if term[i] != term[i+1]:\n",
        "          new_word = term[:i] + term[i+1] + term[i] + term[i+2:]\n",
        "          if new_term in self.lm.unigram_counts:\n",
        "            possible_words.add(new_term)\n",
        "\n",
        "      return list(possible_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zEYvHHBQPxKw",
      "metadata": {
        "id": "zEYvHHBQPxKw"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    می‌توانید تست هایی علاوه بر تست زیر برای ارزیابی اضافه \n",
        "    کنید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f599f01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f599f01",
        "outputId": "80e431b6-2511-4718-fbb6-498dd4c0d32b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1091\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "cg = CandidateGenerator(lm, epm)\n",
        "query = 'sharif university'\n",
        "num_candidates = 0\n",
        "did_generate_original = False\n",
        "\n",
        "for candidate, candidate_logp in cg.get_candidates(query):\n",
        "    num_candidates += 1\n",
        "    if candidate == query:\n",
        "        did_generate_original = True\n",
        "        \n",
        "    if cg.get_num_oov(query) != 0:\n",
        "        print(\"You should not generate queries with out-of-vocab terms ('{}' has OOV terms)\".format(candidate))\n",
        "\n",
        "\n",
        "print(num_candidates)\n",
        "print(did_generate_original)\n",
        "### Begin your code\n",
        "\n",
        "### End your code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2076f83",
      "metadata": {
        "id": "c2076f83"
      },
      "source": [
        "<div dir='rtl'>\n",
        "\n",
        "\n",
        "### IV.4. امتیازدهنده‌ی نامزدها\n",
        "\n",
        "وظیفه امتیازدهنده‌ی نامزدها این است که شبیه‌ترین کوئری $Q$ را به R پیداکند. این‌کار را با ترکیب مدل زبانی  $P(Q)$ و مدل احتمال ویرایش برای $P(R\\mid Q)$ و تولید‌کننده‌ی نامزدها انجام می‌دهد.\n",
        "$$\n",
        "    Q^{*} = \\arg\\max_{Q_{i}} P(Q_{i}\\mid R) = \\arg\\max_{Q_{i}} P(R\\mid Q_{i}) P(Q_{i}),\n",
        "$$\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e4fd5e0",
      "metadata": {
        "id": "6e4fd5e0"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "#### IV.4.1. امتیازدهنده‌ی نامزدها با وزن‌دهی (Candidate Scorer with Weighting)\n",
        "\n",
        "\n",
        "بعد از انجام این ترکیب، ما از یک پارامتر برای وزن‌دادن جداگانه به این دومدل استفاده می‌کنیم.\n",
        "$$\n",
        "    P(Q\\mid R)\\propto P(R\\mid Q)P(Q)^{\\mu}.\n",
        "$$\n",
        "با $\\mu = 1$ شروع کرده و بعدا مقادیر مختلفی را امتحان کنید تا بهترین نتیجه را بگیرید.\n",
        "کد پایین را کامل کنید تا مصحح غلط املایی با uniform edit cost model ساخته شود \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2de033e",
      "metadata": {
        "id": "c2de033e"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CandidateScorer:\n",
        "    \"\"\"Combines the `LanguageModel`, `EditProbabilityModel`, and\n",
        "    `CandidateGenerator` to produce the most likely query Q given a raw query R.\n",
        "    Since the candidate generator already uses the edit probability model, we\n",
        "    do not need to take the edit probability model as an argument in the constructor.\n",
        "    \"\"\"\n",
        "    def __init__(self, lm, cg, mu=1.):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            lm (LanguageModel): Language model for estimating P(Q).\n",
        "            cg (CandidateGenerator): Candidate generator for generating possible Q.\n",
        "            mu (float): Weighting factor for the language model (see write-up).\n",
        "                Remember that our probability computations are done in log-space.\n",
        "        \"\"\"\n",
        "        self.lm = lm\n",
        "        self.cg = cg\n",
        "        self.mu = mu\n",
        "\n",
        "    def get_score(self, query, log_edit_prob):\n",
        "        \"\"\"Uses the language model and `log_edit_prob` to compute the final\n",
        "        score for a candidate `query`. Uses `mu` as weighting exponent for P(Q).\n",
        "\n",
        "        Args:\n",
        "            query (str): Candidate query.\n",
        "            log_edit_prob (float): Log-probability of candidate query given\n",
        "                original query (i.e., log(P(R|Q), where R is `query`).\n",
        "\n",
        "        Returns:\n",
        "            log_p (float): Final score for the query, i.e., the log-probability\n",
        "                of the query.\n",
        "        \"\"\"\n",
        "        ### Begin your code\n",
        "        return log_edit_prob + self.mu * self.lm.get_query_logp(query)\n",
        "        ### End your code\n",
        "\n",
        "    def correct_spelling(self, r):\n",
        "        \"\"\"Corrects spelling of raw query `r` to get the intended query `q`.\n",
        "\n",
        "        Args:\n",
        "            r (str): Raw input query from the user.\n",
        "\n",
        "        Returns:\n",
        "            q (str): Spell-corrected query. That is, the query that maximizes\n",
        "                P(R|Q)*P(Q) under the language model and edit probability model,\n",
        "                restricted to Q's generated by the candidate generator.\n",
        "        \"\"\"\n",
        "\n",
        "        ### Begin your code\n",
        "        flag = True\n",
        "        r_splitted = r.split()\n",
        "\n",
        "        for word in r_splitted:\n",
        "          if word not in self.lm.unigram_counts:\n",
        "            flag = False\n",
        "        \n",
        "        if flag:\n",
        "          return r\n",
        "\n",
        "        max_score = -math.inf\n",
        "        best_candidate = \"\"\n",
        "        for candidate, candidate_logp in self.cg.get_candidates(r):\n",
        "          candid_score = self.get_score(candidate, candidate_logp)\n",
        "          if candid_score > max_score:\n",
        "            best_candidate = candidate\n",
        "            max_score = candid_score\n",
        "        \n",
        "        return best_candidate\n",
        "        \n",
        "        ### End your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174eb40e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "174eb40e",
        "outputId": "06df2339-e587-4e68-ff64-fa8556c14d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building edit probability model...\n",
            "Building candidate generator...\n",
            "Building candidate scorer model...\n",
            "Running spelling corrector...\n",
            "\t'sharaf university' corrected to 'sharad university'\n",
            "\t'sharif university' corrected to 'sha if university'\n",
            "\t'theend of an' corrected to 'the nd of and'\n"
          ]
        }
      ],
      "source": [
        "# Assumes LanguageModel lm was already built above\n",
        "print('Building edit probability model...')\n",
        "epm = UniformEditProbabilityModel()\n",
        "print('Building candidate generator...')\n",
        "cg = CandidateGenerator(lm, epm)\n",
        "print('Building candidate scorer model...')\n",
        "cs = CandidateScorer(lm, cg, mu=1.0)\n",
        "print('Running spelling corrector...')\n",
        "\n",
        "# Add your own queries here to test your spelling corrector\n",
        "queries = [('sharaf university', ' sharif university'),\n",
        "           ('sharif university', ' sharif university'),\n",
        "           ('theend of an', 'the end of an')\n",
        "           ]\n",
        "for query, expected in queries:\n",
        "    corrected = cs.correct_spelling(query)\n",
        "    print(\"\\t'{}' corrected to '{}'\".format(query, corrected))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1cf3de1",
      "metadata": {
        "id": "a1cf3de1"
      },
      "source": [
        "#### IV.4.2. Dev Set Evaluation (Uniform)\n",
        "\n",
        "</div>\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "حال ما یک تصحیح‌گر غلط املایی اولیه را ساختیم.\n",
        "برای ارزیابی مدل خود, سل‌های زیر را اجرا کنید (در صورت داشتن دقت بالاتر از ۷۸٪, حداقل ۵ و حداکثر ۱۵درصد نمره امتیازی به شما داده می‌شود(در صورتی که گروه‌های کمی به این دقت رسیدند, نمره امتیازی به صورت رقابتی داده‌خواهد شد)). \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05b2639",
      "metadata": {
        "id": "b05b2639"
      },
      "outputs": [],
      "source": [
        "def dev_eval(candidate_scorer, verbose=False):\n",
        "    \"\"\"Evaluate `candidate_scorer` on the dev set.\"\"\"\n",
        "    query_num = 1\n",
        "    yours_correct = 0\n",
        "    google_correct = 0\n",
        "    # Read originals, ground-truths, Google's predictions\n",
        "    dev_dir = 'MIR2-data/dev_set/'\n",
        "    with tqdm(total=455, unit=' queries') as pbar, \\\n",
        "            open(os.path.join(dev_dir, 'queries.txt'), 'r') as query_fh, \\\n",
        "            open(os.path.join(dev_dir, 'gold.txt'), 'r') as gold_fh, \\\n",
        "            open(os.path.join(dev_dir, 'google.txt'), 'r') as google_fh:\n",
        "        while True:\n",
        "            # Read one line\n",
        "            query = query_fh.readline().rstrip('\\n')\n",
        "            if not query:\n",
        "                # Finished all queries\n",
        "                break\n",
        "            corrected = candidate_scorer.correct_spelling(query)\n",
        "            corrected = ' '.join(corrected.split())  # Squash multiple spaces\n",
        "            gold = gold_fh.readline().rstrip('\\n')\n",
        "            google = google_fh.readline().rstrip('\\n')\n",
        "\n",
        "            # Count whether correct\n",
        "            if corrected == gold:\n",
        "                yours_correct += 1\n",
        "            if google == gold:\n",
        "                google_correct += 1\n",
        "\n",
        "            # Print running stats\n",
        "            yours_accuracy = yours_correct / query_num * 100\n",
        "            google_accuracy = google_correct / query_num * 100\n",
        "            if verbose:\n",
        "                print('QUERY {:03d}'.format(query_num))\n",
        "                print('---------')\n",
        "                print('(original):      {}'.format(query))\n",
        "                print('(corrected):     {}'.format(corrected))\n",
        "                print('(google):        {}'.format(google))\n",
        "                print('(gold):          {}'.format(gold))\n",
        "                print('Google accuracy: {}/{} ({:5.2f}%)\\n'\n",
        "                      .format(google_correct, query_num, google_accuracy))\n",
        "                print('Your accuracy:   {}/{} ({:5.2f}%)'\n",
        "                      .format(yours_correct, query_num, yours_accuracy))\n",
        "            \n",
        "            pbar.set_postfix(google='{:5.2f}%'.format(google_accuracy),\n",
        "                             yours='{:5.2f}%'.format(yours_accuracy))\n",
        "            pbar.update()\n",
        "            query_num += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85dc5ee2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "85dc5ee2",
        "outputId": "b07b3ddb-47ff-458c-c90a-d6e7b9d7a1f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 411/455 [52:56<05:40,  7.73s/ queries, google=82.73%, yours=3.89%]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-305d1b7c2038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set verbose=True for debugging output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdev_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-100-d9170f4338c5>\u001b[0m in \u001b[0;36mdev_eval\u001b[0;34m(candidate_scorer, verbose)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;31m# Finished all queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcorrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrect_spelling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mcorrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Squash multiple spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgold_fh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-7e9a1dd9f3a2>\u001b[0m in \u001b[0;36mcorrect_spelling\u001b[0;34m(self, r)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mbest_candidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_logp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m           \u001b[0mcandid_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_logp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mcandid_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-5b0b25d2c0d2>\u001b[0m in \u001b[0;36mget_candidates\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mnew_query_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mquery_splitted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuggested_term_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mquery_splitted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuggested_term_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mquery_splitted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mnew_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_query_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_and_yield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_query_edit_logp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m### End your code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-6b4f8b71ef54>\u001b[0m in \u001b[0;36mget_query_edit_logp\u001b[0;34m(self, edited, original)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mterm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medited\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m           \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_edit_logp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-6b4f8b71ef54>\u001b[0m in \u001b[0;36mget_edit_logp\u001b[0;34m(self, edited, original)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m               \u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set verbose=True for debugging output\n",
        "dev_eval(cs, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ed4a81",
      "metadata": {
        "id": "55ed4a81"
      },
      "source": [
        "<a id='empirical'></a>\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "##  تصحیح املا با هزینه‌های ویرایش تجربی\n",
        "\n",
        "### V.1. مدل احتمال ویرایش بهبودیافته (Improved Edit Probability Model)\n",
        "\n",
        "\n",
        "</div>\n",
        "<div dir='rtl'>\n",
        "حال که تصحیح‌کننده غلط املایی ما با یک مدل احتمالاتی ویرایش اولیه(edit probability model) به درستی کار می‌کند, برای ویرایش احتمالات به سمت یک رویکرد کاربردی‌تر می‌رویم. برای این بخش و learn کردن این احتمال ویرایش‌ها ما از داده‌ی خطای تجربی که در  \n",
        "`data/training_set/edit1s.txt` قراردارد استفاده می‌کنیم\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af0d9ccb",
      "metadata": {
        "id": "af0d9ccb"
      },
      "source": [
        "<div dir='rtl'>\n",
        "\n",
        "#### V.1.1. هزینه‌ها‌ی ویرایش تجربی (Empirical Edit Costs) \n",
        "</div>\n",
        "\n",
        "<div dir='rtl'>\n",
        "\n",
        "\n",
        "\n",
        "یک لیست از جفت کوئری‌هایی که فاصله‌یشان از یکدیگر دقیقا ۱ است به شما داده شده است. در قدم اول یک الگوریتم ساده برای تعیین کردن این که کدام ویرایش بخصوص میان دو کوئری در هر جفت وجود دارد پیاده‌سازی کنید. با جمع کردن شمارش تمام ویرایش‌های این‌چنینی در تمام کوئری‌ها احتمال هر ویرایش قابل محاسبه خواهد بود. به عنوان مثال، اگر خواستید تعیین کنید که احتمال جایگزین شدن اشتباهی حرف 'e' با حرف 'a' در یک کوئری چقدر است، باید مقدار زیر را محاسبه کنید:\n",
        "$$\n",
        "    P(\\texttt{sub}[a, e]) = \\frac{\\texttt{count}(\\texttt{sub}[a, e])}{\\texttt{count}(e)}.\n",
        "$$\n",
        "با توجه به این که احتمال عملیات‌های درج و حذف به حروف قبل از حرفی که روی آن عملی انجام می‌شود مشروطند، پس باید راه‌حل مناسبی برای حذف و درج در ابتدای یک لغت ارائه دهید. در نهایت برای رفع مشکل پراکندگی داده‌ها در فایل training روش هموارسازی Laplace add-one را برای احتمالات ویرایش پیاده‌سازی کنید."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ccb999",
      "metadata": {
        "id": "99ccb999"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Edit:\n",
        "    \"\"\"Represents a single edit in Damerau-Levenshtein distance.\n",
        "    We use this class to count occurrences of different edits in the training data.\n",
        "    \"\"\"\n",
        "    INSERTION = 1\n",
        "    DELETION = 2\n",
        "    TRANSPOSITION = 3\n",
        "    SUBSTITUTION = 4\n",
        "\n",
        "    def __init__(self, edit_type, c1=None, c2=None):\n",
        "        \"\"\"\n",
        "        Members:\n",
        "            edit_type (int): One of Edit.{NO_EDIT,INSERTION,DELETION,\n",
        "                TRANSPOSITION,SUBSTITUTION}.\n",
        "            c1 (str): First (in original) char involved in the edit.\n",
        "            c2 (str): Second (in original) char involved in the edit.\n",
        "        \"\"\"\n",
        "        self.edit_type = edit_type\n",
        "        self.c1 = c1\n",
        "        self.c2 = c2\n",
        "\n",
        "\n",
        "class EmpiricalEditProbabilityModel(BaseEditProbabilityModel):\n",
        "\n",
        "    START_CHAR = ''      # Used to indicate start-of-query\n",
        "    NO_EDIT_PROB = 0.92  # Hyperparameter for probability assigned to no-edit\n",
        "\n",
        "    def __init__(self, training_set_path='MIR2-data/training_set/edit1s.txt'):\n",
        "        \"\"\"Builds the necessary data structures to compute log-probabilities of\n",
        "        distance-1 edits in constant time. In particular, counts the unigrams\n",
        "        (single characters), bigrams (of 2 characters), alphabet size, and\n",
        "        edit count for insertions, deletions, substitutions, and transpositions.\n",
        "\n",
        "        Hint: Use the `Edit` class above. It may be easier to write the `get_edit`\n",
        "        function first, since you should call that function here.\n",
        "\n",
        "        Note: We suggest using tqdm with the size of the training set (819722) to track\n",
        "        the initializers progress when parsing the training set file.\n",
        "\n",
        "        Args:\n",
        "            training_set_path (str): Path to training set of empirical error data.\n",
        "        \"\"\"\n",
        "        # Your code needs to initialize all four of these data structures\n",
        "        self.unigram_counts = Counter()  # Maps chars c1 -> count(c1)\n",
        "        self.bigram_counts = Counter()   # Maps tuples (c1, c2) -> count((c1, c2))\n",
        "        self.alphabet_size = 0           # Counts all possible characters\n",
        "\n",
        "        # Maps edit-types -> dict mapping tuples (c1, c2) -> count(edit[c1, c2])\n",
        "        # Example usage: \n",
        "        #   > e = Edit(Edit.SUBSTITUTION, 'a', 'b')\n",
        "        #   > edit_count = self.edit_counts[e.edit_type][(e.c1, e.c2)]\n",
        "        self.edit_counts = {edit_type: Counter()\n",
        "                            for edit_type in (Edit.INSERTION, Edit.DELETION,\n",
        "                                              Edit.SUBSTITUTION, Edit.TRANSPOSITION)}\n",
        "\n",
        "        with open(training_set_path, 'r') as training_set:\n",
        "            for example in tqdm(training_set, total=819722):\n",
        "                edited, original = example.strip().split('\\t')\n",
        "\n",
        "                ### Begin your code\n",
        "\n",
        "                ### End your code\n",
        "\n",
        "    def get_edit(self, edited, original):\n",
        "        \"\"\"Gets an `Edit` object describing the type of edit performed on `original`\n",
        "        to produce `edited`.\n",
        "\n",
        "        Note: Only edits with an edit distance of at most 1 are valid inputs.\n",
        "\n",
        "        Args:\n",
        "            edited (str): Raw query, which contains exactly one edit from `original`.\n",
        "            original (str): True query. Want to find the edit which turns this into `edited`.\n",
        "\n",
        "        Returns:\n",
        "            edit (Edit): `Edit` object representing the edit to apply to `original` to get `edited`.\n",
        "                If `edited == original`, returns None.\n",
        "        \"\"\"\n",
        "        ### Begin your code\n",
        "\n",
        "        ### End your code\n",
        "\n",
        "    def get_edit_logp(self, edited, original):\n",
        "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
        "        The `original` and `edited` arguments are both single terms that are at\n",
        "        most one edit apart.\n",
        "        \n",
        "        Note: The order of the arguments is chosen so that it reads like an\n",
        "        assignment expression:\n",
        "            > edited := EDIT_FUNCTION(original)\n",
        "        or, alternatively, you can think of it as a (unnormalized) conditional probability:\n",
        "            > log P(edited | original)\n",
        "\n",
        "        Args:\n",
        "            edited (str): Edited term.\n",
        "            original (str): Original term.\n",
        "\n",
        "        Returns:\n",
        "            logp (float): Log-probability of `edited` given `original`\n",
        "                under this `EditProbabilityModel`.\n",
        "        \"\"\"\n",
        "        ### Begin your code\n",
        "\n",
        "        ### End your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6159e772",
      "metadata": {
        "id": "6159e772"
      },
      "outputs": [],
      "source": [
        "# Build spelling corrector for evaluation on the dev set\n",
        "lm = LanguageModel()\n",
        "epm = EmpiricalEditProbabilityModel()\n",
        "cg = CandidateGenerator(lm, epm)\n",
        "cs = CandidateScorer(lm, cg, mu=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iMXmGw8jPxLY",
      "metadata": {
        "id": "iMXmGw8jPxLY"
      },
      "source": [
        "<div dir='rtl'>\n",
        "     . در صورت داشتن دقت بالاتر از 79٪, ۵ تا ۱۵درصد نمره امتیازی به شما داده می‌شود (در صورتی که گروه‌های کمی به این دقت رسیدند, نمره امتیازی به صورت رقابتی داده‌خواهد شد)\n",
        "    </div"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "890f3261",
      "metadata": {
        "id": "890f3261"
      },
      "outputs": [],
      "source": [
        "# Set verbose=True for debugging output\n",
        "dev_eval(cs, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LSJy5yUnPxLb",
      "metadata": {
        "id": "LSJy5yUnPxLb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ZzpRsmsSPxLc",
      "metadata": {
        "id": "ZzpRsmsSPxLc"
      },
      "source": [
        "<a id='written'></a>\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "##  گزارش مکتوب\n",
        "\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "در این بخش انتظار می‌رود که شما گزارشی از کارهای انجام شده در هر تسک - نتایج گرفته شده و ایده‌هایی که استفاده کردید و نیز تغییرات داده شده در کد(در صورت وجود) بنویسید. این بخش ۱۵درصد نمره شما را خواهد داشت\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j5Hi_zdOkeJM",
      "metadata": {
        "id": "j5Hi_zdOkeJM"
      },
      "source": [
        "<a id='written'></a>\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "## تسک اول : تصحیح املا با استفاده از Uniform Edit Costs\n",
        "\n",
        "</div>\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "### مدل زبان\n",
        "\n",
        "می‌دانیم که برای یافتن بهترین اصلاح Q، باید P(Q) را محاسبه کنیم.\n",
        "طبق فرمولی که در ابتدای بخش داده‌شده‌است، برای محاسبه‌ی این احتمال باید احتمال تک کلمات (unigram) و ترکیبات دوتایی کلمات (bigram) را محاسبه کنیم.\n",
        "در این بخش کلاس language model را می‌سازیم که در آن با استفاده از counter، هرکلمه را به همراه تعداد تکرارش در یک دیکشنری ذخیره می‌کنیم.\n",
        "برای ترکیبات دوتایی نیز از همین روش استفاده می‌کنیم و برای هر ترکیب دوتایی از کلمات، تعداد تکرارشان را نگه می‌داریم. درنهایت تعداد کل کلمات موجود در corpus را نیز به‌دست می‌آوریم.\n",
        "\n",
        "### هموارسازی با استفاده از درون‌یابی\n",
        "در بخش قبل ما فرض کردیم که تمامی کلماتی که در کوئری پیشنهادی ما (Q) می‌آیند، در corpus حضور دارند و بنابراین احتمال آن‌ها را برابر با تعداد تکرارشان تقسیم بر تعداد کل کلمات در نظر گرفتیم. اما برای تکریبات دوتایی نمی‌توان از این فرمول استفاده کرد چون ممکن است که یک ترکیب دوتایی از کلمات در هیج بخش از corpus نیامده باشند و درنتیجه احتمال آن ترکیب صفر می‌شود و بنابراین آن ترکیب را کلا کار می‌گذاریم درصورتیکه در واقعیت ‌می‌دانیم که این احتمال نباید صفر باشد. به همین علت عملیات هموارسازی را انجام می‌دهیم.\n",
        "\n",
        "### مدل احتمال ویرایش\n",
        "در این بخش کلاس UniformedProbabilityModel نوشته‌شد که در آن ما edit_prob را برابر با ۰.۰۵ درنظر گرفتیم چون در خود سوال هم مطرح شده‌بود که به احتمال بالایی خود کوئری‌ها درست هستند و نیازی به تغییر ندارند. پس از آن تابع get_edit_logp را نوشتیم که دو رشته ورودی می‌گیرد و edit distanced آن‌ها را محاسبه می‌کند. درصورتیکه فاصله‌شان صفر بود، احتمال\n",
        "edit_prob - 1\n",
        "و درصورتیکه فاصله‌شان یک بود، خود edit_prob و درغیراین‌صورت صفر را خروجی می‌دهد.\n",
        "البته به منظور کاهش مقادیر به جای خودشان، لگاریتم‌شان را برمی‌گردانیم.\n",
        "در تابع get_query_edit_logp هم دو کوئری رادریافت می‌کنیم و تک‌‌تک فاصله‌ی بین اعضایش را محاسبه می‌کنیم. در اینجا فرض می‌کنیم که هردو کوئری دارای تعداد اعضای یکسان هستند. (درواقع لیست‌شان را به‌گونه‌ای درست می‌کنیم که تعداد عضوهایش ثابت بمانند.)\n",
        "### تولیدکننده‌ی نامزدها\n",
        "در این بخش ما کوئری‌های پیشنهادی‌مان را تولید می‌کنیم. البته همانطور که در خود سوال هم مطرح شده‌است، فقط کوئری‌های با فاصله‌ی دو از کوئری اصلی را در نظر می‌گیریم. (یعنی کوئری‌هایی که حداکثر دو کلمه از کوئری اول را تغییر داده‌باشند)\n",
        "همچنین به منظور تولید کوئری‌ها چهار عملیات را در نظر می‌گیریم:\n",
        "- Addition: در این عملیات هربار یک حرف به بخشی از کلمه اضافه می‌کنیم. توجه داریم که در این بخش امکان افزودن فاصله و «-» نیز هست چون ممکن است کاربر به اشتباه یکی از آن‌ها را جا انداخته باشد.\n",
        "- subtraction: هربار یکی از حروف کلمه را حذف می‌کنیم.\n",
        "- Substitution: هربار یکی از حروف کلمه را با یکی از حروف الفبا که در خود کلاس داده‌شده است، تعویض می‌کنیم. دراینجا نیز امکان اضافه کردن فاصله و «-» به کلمات هست. \n",
        "- transposition:\n",
        "در این بخش هربار هردو حرف کناری را جابجا می‌کنیم.\n",
        "\n",
        "توجه داریم که در دو عملیات آخر، بررسی می‌کنیم که حرفی که میخواهیم با آن جایگزینی/جابجایی را انجام دهیم، تکراری نباشد وگرنه عملیات بیهوده‌است.\n",
        "همچنین تنها کلماتی را در نهایت ذخیره می‌کنیم که در corpus باشند.\n",
        "\n",
        "برای پیاده‌سازی عملیات‌های بالا، تابع get_distance_one_terms را زدیم و درنهایت این تابع را یک‌بار فقط برای یکی از کلمات کوئری و بار دیگر برای دو کلمه از کلمات کوئری می‌نویسیم.\n",
        "درنهایت حالتی را هم که ممکن است دو کلمه‌ی پشت هم از کوئری اشتباها با فاصله آمده‌باشند را نیز پیاده‌ کردیم و هربار هردو کلمه‌ی پشت هم را به‌هم می‌چسبانیم و سپس بررسی می‌کنیم که ترکیب معناداری هست یا خیر. اگر بود آن را نیز به کوئری‌های پیشنهادی اضافه می‌کنیم.\n",
        "### امتیازدهنده‌ی نامزدها\n",
        "درنهایت باید به کوئری‌هایی که به‌دست‌آوردیم امتیاز بدهیم که برای این‌کار از فرمولی که داده‌شده است استفاده می‌کنیم. در تابع get_score امتیاز یک کوئری را حساب می‌کنیم. در تابع correct-spelling، تمامی کوئری‌های پیشنهادی را دریافت می‌کنیم و هربار چک می‌کنیم که امتیاز کدام یک بیشتر است. درنهایت کوئری‌ای که دارای بیشترین امتیاز است را برمیگردانیم.\n",
        "دراین بخش دقت نهایی ما ۷۸.۰۲ شد.\n",
        "## تسک دوم : تصحیح املا با هزینه‌های ویرایش تجربی\n",
        "برای تشخیص عملیاتی که یکی از کوئری‌ها را به دیگری تبدیل می‌کند، تابع get_edit زده‌شد. در این تابع ما ابتدا بررسی می‌کنیم که دو کوئری یکسان هستند یا خیر. درصورتیکه یکسان باشند عملیاتNone است. پس از آن بررسی می‌کنیم که درصورتیکه طول کوئری اصلاح‌شده بیشتر باشد، عملیات حتما addition است. اگر طول کوئری اصلاح‌شده از طول کوئری اصلی کمتر باشد، عملیات حتما subtraction است. درغیراین‌صورت اگر تفاوت دو کوئری در دو حرف به صورت ضربدری باشد، عملیات transposition وگرنه عملیات substitution است. \n",
        "در تمامی عملیات‌های بالا برای یافتن حرف تغییر یافته، روی کوئری for می‌زنیم تا به اولین کاراکتری که در دو ورودی تفاوت دارد، برسیم.\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
