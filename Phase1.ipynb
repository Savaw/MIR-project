{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5O3xz7oPosg"
      },
      "source": [
        "<div style=\"direction:rtl;line-height:300%;font-family:BNazanin,\">\n",
        "<font face=\"XB Zar\" size=5>\n",
        "<div align=center>\n",
        "<font face=\"B Titr\" size=5>\n",
        "<p></p><p></p>\n",
        "بسمه تعالی\n",
        "<p></p>\n",
        "</font>\n",
        "<p></p>\n",
        "<font>\n",
        "<br>\n",
        "درس بازیابی پیشرفته اطلاعات\n",
        "<br>\n",
        "مدرس: دکتر فاطمه لشکری\n",
        "</font>\n",
        "<p></p>\n",
        "<br>\n",
        "<font>\n",
        "<b>فاز اول پروژه</b>\n",
        "</font>\n",
        "<br>\n",
        "<br>\n",
        "موعد تحویل: ۸ آبان ۱۴۰۰\n",
        "<br>\n",
        "<font size=4.8>\n",
        "دستیاران آموزشی مربوط به این فاز: سینا کاظمی - پارسا اسکندر\n",
        "</font>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<font>\n",
        "دانشگاه صنعتی شریف\n",
        "<br>\n",
        "دانشکده مهندسی کامپیوتر\n",
        "<br>\n",
        "<br>\n",
        "</font>\n",
        "</div>\n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i47HeS9NRU7B"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "مقدمه\n",
        "</h2>\n",
        "<p>\n",
        "هدف فاز اول پروژه پیاده سازی یک سیستم بازیابی اطلاعات است.\n",
        "این فاز پروژه از ۴ مرحله تشکیل شده است.\n",
        "بخش اول به پیش پردازش متنی داده ها می پردازد که شامل نرمال سازی متن (Normalization) ، جداسازی لغات (Tokenization) ، حذف لغات پرتکرار و ... می باشد. بخش دوم مربوط به نمایه سازی (indexing) خواهد بود. در بخش سوم باید روی این نمایه فشرده سازی صورت بگیرد. در بخش چهارم باید پرسمان ورودی کاربر را تصحیح کنید.\n",
        "</p>\n",
        "<p>\n",
        "۲ سری مجموعه دادگان در اختیار شما قرار گرفته است که یکی مربوط به زبان فارسی ( persian_dataset.csv ) و دیگری مربوط به زبان انگلیسی ( english_dataset.csv ) می باشد.\n",
        "مجموعه فارسی بخشی از مستندات ویکی پدیای فارسی می باشد و مجموعه انگلیسی مربوط به اخبار است.\n",
        "</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi2P02O_RviE"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش اول ( پیش پردازش اولیه متن )\n",
        "</h2>\n",
        "<p>\n",
        "در این بخش از پروژه باید ابتدا مجموعه فایل هایی که در اختیارتان قرار گرفته است را بخوانید، برای خواندن و کار کردن با فایل‌ها پیشنهاد می‌شود از کتابخانه‌ی \n",
        "<a href=\"https://pandas.pydata.org/\">\n",
        "pandas\n",
        "</a> \n",
        "استفاده کنید.\n",
        "این کتابخانه توابعی برای \n",
        "<a href=\"https://www.geeksforgeeks.org/python-read-csv-using-pandas-read_csv/\">\n",
        "خواندن\n",
        "</a> \n",
        "و \n",
        "<a href=\"https://towardsdatascience.com/pandas-dataframe-basics-3c16eb35c4f3\">\n",
        "کار کردن\n",
        "</a> \n",
        "راحت‌تر با دیتاها در اختیار شما قرار می‌دهد .\n",
        "\n",
        "\n",
        " سپس به ترتیب مراحل پیش پردازش متنی که در ادامه آمده است را روی آنها اعمال کنید. برای کار های پیش رو می توانید از کتابخانه های \n",
        "<a href=\"https://www.nltk.org/\">\n",
        "NLTK\n",
        "</a>\n",
        " برای زبان انگلیسی و هضم ( \n",
        "   <a href=\"http://www.sobhe.ir/hazm/\">\n",
        "hazm\n",
        "</a> \n",
        " ) برای زبان فارسی استفاده کنید\n",
        "</p>\n",
        "<ul>\n",
        "<li>\n",
        "نرمال سازی متنی (normalization): برای یکسان سازی متون می توانید از توابع معرفی شده استفاده کنید. اما در صورتی که میخواهید خودتان پیاده سازی کنید باید پیاده \n",
        "سازیتان شامل برگرداندن لغات به ریشه (stemming)\n",
        "، case folding ( برای یکسان سازی متون انگلیسی ) و بقیه موارد مطرح شده در درس باشد.\n",
        "</li>\n",
        "<li>\n",
        "جداسازی (tokenization): برای اینکار میتوانید از کتابخانه های معرفی شده در بالا استفاده نمایید\n",
        "</li>\n",
        "<li>\n",
        "حذف علائم نگارشی: هر متنی در هر زبانی یه سری علائم نگارشی دارد که می بایست حذف شوند مانند: ویرگول ، دونقطه و ...\n",
        "</li>\n",
        "<li>\n",
        "یافتن و حذف لغات پرتکرار (stopwords): در این بخش، حذف درصد معقولی از لغات پرتکرار مورد نظر است. برای این منظور لازم است تا همه متن را پردازش کنید و نسبت به حجم متن، کلماتی که پرتکرار هستند را نمایش دهید. این نسبت را طوری در نظر بگیرید که کلمات پرتکرار به دست آمده تا حد خوبی منطقی و کافی باشند.\n",
        "</li>\n",
        "<li>\n",
        "برگرداندن کلمات به ریشه (stemming, lemmatizing): در نهایت کلمات را به حالت ساده و پایه آنها تبدیل کنید.\n",
        "</li>\n",
        "</ul>\n",
        "<p>\n",
        "برای پیاده سازی این بخش تابع پیاده سازی prepare_text را پر کنید.\n",
        "برای نمایش لغات پرتکرار می توانید از هیستوگرام و یا لیست ساده ای از کلمات استفاده کنید.\n",
        "</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IA4boCankmT"
      },
      "source": [
        "# Prerequisite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkaG5V68C4HE"
      },
      "source": [
        "Colab link: https://colab.research.google.com/drive/1vFlN-hhMYCxSKdSLXIdeWmPMzMzcQl41?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRVbZ6gBnAlw"
      },
      "outputs": [],
      "source": [
        "colab = True\n",
        "# if you are using google colab, create a directory named MIR in your \n",
        "# drive containing english_dataset.csv and persian_dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5oVINftnAly",
        "outputId": "ed6fbaa1-6337-4d35-f6c2-5b5ba7a1cc0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "base_dir = ''\n",
        "if colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_dir = '/content/drive/MyDrive/MIR/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNa_DIUItNLP"
      },
      "source": [
        "Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRJtenNmnR4p",
        "outputId": "769f7fd2-6416-4692-bd28-a212f5f09e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 40.8 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 19.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394488 sha256=5f0217e161d7ab36cf24e819d9b856fbcb9554b4678ca7e02a1755b2aec3ebc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154788 sha256=45ee8665d368a9410d56e35453d20eeb162ffd7cf897946bd957a8f7694ab857\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n",
            "Collecting PersianStemmer\n",
            "  Downloading persianstemmer-1.0.0.tar.gz (810 kB)\n",
            "\u001b[K     |████████████████████████████████| 810 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting patricia-trie\n",
            "  Downloading patricia-trie-10.tar.gz (6.7 kB)\n",
            "Building wheels for collected packages: PersianStemmer, patricia-trie\n",
            "  Building wheel for PersianStemmer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PersianStemmer: filename=PersianStemmer-1.0.0-py3-none-any.whl size=810282 sha256=80e4c7949344e1bf05d77d25d6c9e566dc20b7275c12249862e2de41777e8fe1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f7/96/55f0070725e6ce1191aa9a931e962fc0f551b68ed919fb7f8e\n",
            "  Building wheel for patricia-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for patricia-trie: filename=patricia_trie-10-py3-none-any.whl size=7767 sha256=665d30d769c752f70f1cd2611049cdc8c82c0fbb154bdd3e7876d36337f9614b\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/89/b4/46456cda461ffee3f6ef09a68bccb5d175b65ff2b922b5b5b8\n",
            "Successfully built PersianStemmer patricia-trie\n",
            "Installing collected packages: patricia-trie, PersianStemmer\n",
            "Successfully installed PersianStemmer-1.0.0 patricia-trie-10\n",
            "Collecting parsivar\n",
            "  Downloading parsivar-0.2.3.tar.gz (36.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.2 MB 68 kB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->parsivar) (1.15.0)\n",
            "Building wheels for collected packages: parsivar, nltk\n",
            "  Building wheel for parsivar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsivar: filename=parsivar-0.2.3-py3-none-any.whl size=36492971 sha256=3727b2247d356c017e570f9e6273f4dc9af619666d422e0131e6910a820d1f1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/67/7a/49cbf08f64d3f76a26eceaf0e481a40e233f05d4356875cbed\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449921 sha256=86f3a4ba29db08ed10ac9f6fdf1b8791c4b5672ff80ecff81e18568156b59142\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "Successfully built parsivar nltk\n",
            "Installing collected packages: nltk, parsivar\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.3\n",
            "    Uninstalling nltk-3.3:\n",
            "      Successfully uninstalled nltk-3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "hazm 0.7.0 requires nltk==3.3, but you have nltk 3.4.5 which is incompatible.\u001b[0m\n",
            "Successfully installed nltk-3.4.5 parsivar-0.2.3\n",
            "Collecting arabic-reshaper\n",
            "  Downloading arabic_reshaper-2.1.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from arabic-reshaper) (57.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from arabic-reshaper) (0.16.0)\n",
            "Installing collected packages: arabic-reshaper\n",
            "Successfully installed arabic-reshaper-2.1.3\n",
            "Collecting python-bidi\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-bidi) (1.15.0)\n",
            "Installing collected packages: python-bidi\n",
            "Successfully installed python-bidi-0.4.2\n",
            "Collecting unary_coding\n",
            "  Downloading unary_coding-1.0.3.tar.gz (2.8 kB)\n",
            "Building wheels for collected packages: unary-coding\n",
            "  Building wheel for unary-coding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unary-coding: filename=unary_coding-1.0.3-py3-none-any.whl size=2865 sha256=2a2b485f5cc521715c72ff0217456d468761454c286a8cc09bceaa3652c70f47\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/14/6b/3ba14433885a1b1665a3d46d4774f57f5ed415ea4cede61563\n",
            "Successfully built unary-coding\n",
            "Installing collected packages: unary-coding\n",
            "Successfully installed unary-coding-1.0.3\n",
            "Collecting bitstring\n",
            "  Downloading bitstring-3.1.9-py3-none-any.whl (38 kB)\n",
            "Installing collected packages: bitstring\n",
            "Successfully installed bitstring-3.1.9\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install hazm\n",
        "!pip install PersianStemmer\n",
        "!pip install parsivar\n",
        "!pip install arabic-reshaper\n",
        "!pip install python-bidi\n",
        "!pip install unary_coding\n",
        "!pip install bitstring\n",
        "!pip install pandas\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN4tRUhDod0R"
      },
      "source": [
        "File Reading & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiK6bzZHh0zA",
        "outputId": "0aff9e1a-6b40-417a-8ad2-63d488ec7b45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import string\n",
        "import nltk\n",
        "import os\n",
        "import pandas as pd\n",
        "import parsivar as prv\n",
        "from unary_coding import unary, inverted_unary\n",
        "from bidi.algorithm import get_display\n",
        "from arabic_reshaper import reshape\n",
        "from PersianStemmer import PersianStemmer \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import PorterStemmer,SnowballStemmer,LancasterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import words\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from __future__ import unicode_literals\n",
        "from hazm import *\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "\n",
        "farsi_txt_all = pd.read_csv(base_dir + \"persian_dataset.csv\")\n",
        "farsi_txt_all.columns = ['title','text']\n",
        "farsi_txt = farsi_txt_all\n",
        "# farsi_txt = farsi_txt_all[:100]\n",
        "\n",
        "english_txt_all = pd.read_csv(base_dir + \"english_dataset.csv\")\n",
        "english_txt = english_txt_all\n",
        "# english_txt = english_txt_all[:100]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEw2e-ie24ZK",
        "outputId": "bb48f9e8-3497-4a03-8aeb-0a4853b4dc62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15000 entries, 0 to 14999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   title   15000 non-null  object\n",
            " 1   text    15000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 234.5+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6335 entries, 0 to 6334\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  6335 non-null   int64 \n",
            " 1   title       6335 non-null   object\n",
            " 2   text        6335 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 148.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(farsi_txt.info())\n",
        "print(english_txt.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3mzcs6R-hCO"
      },
      "outputs": [],
      "source": [
        "debug = False\n",
        "def dprint(*args):\n",
        "    if debug:\n",
        "        print(*args, sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6X7sAZKtQf-"
      },
      "source": [
        "# Pre-Process Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWxLOYIK7kmP"
      },
      "outputs": [],
      "source": [
        "import abc\n",
        "\n",
        "class Preprocessor(abc.ABC):\n",
        "    def __init__(self, text_df):\n",
        "        self.text_df = text_df\n",
        "        self.punctuation = string.punctuation + \"‘’“”–‹›°؟،؛»«\"\n",
        "        self.stop_words = []\n",
        "\n",
        "    def _remove_punctuation_from_word(self, punctuation, word):\n",
        "        return ''.join([c for c in word if c != punctuation])\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def basic_text_preprocess(self, raw_text, normalize=True,\n",
        "                                             remove_punctuation=True,\n",
        "                                             stem=True,\n",
        "                                             lemmatize=True):\n",
        "        \"\"\"Preprocesses the text with tokenization, case folding, stemming and lemmatization\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        raw_text : df column (pandas.core.series.Series)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        df column\n",
        "            Tokenized pandas dataframe\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def get_words_frequency(self, limit=50):\n",
        "        \"\"\"Return top `limit` words with most frequency \n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list of tuple\n",
        "            A list of tuples containing tokens and their frequencies\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"preprocessing title tokens...\")\n",
        "        title_tokens = self.basic_text_preprocess(self.text_df['title'])\n",
        "\n",
        "        print(\"preprocessing context tokens...\")\n",
        "        context_tokens = self.basic_text_preprocess(self.text_df['text'])\n",
        "\n",
        "        print(\"preprocessing done.\")\n",
        "\n",
        "        all_tokens = pd.concat([title_tokens, context_tokens])\n",
        "\n",
        "        # find frequency\n",
        "        freq = nltk.FreqDist()\n",
        "        all_tokens.apply(lambda text: freq.update(nltk.FreqDist(w for w in text)))\n",
        "\n",
        "        freqs = freq.most_common()[:limit]\n",
        "\n",
        "        plt.rcParams['figure.figsize'] = [25, 5]\n",
        "\n",
        "        labels, values = list(zip(*freqs))\n",
        "        labels = [get_display(reshape(label)) for label in labels]\n",
        "        plt.bar(labels, values)\n",
        "        plt.xticks(rotation=70)\n",
        "        plt.show()\n",
        "\n",
        "        return freqs[:limit]\n",
        "\n",
        "\n",
        "    def get_and_set_stop_words(self, words_frequencies, limit):\n",
        "        \"\"\"Return stop words\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of stop words and their frequencies\n",
        "        \"\"\"\n",
        "\n",
        "        most_common = words_frequencies[:limit]\n",
        "        most_common_dict = {word:freq for word, freq in most_common}\n",
        "        self.stop_words = most_common_dict.keys()\n",
        "\n",
        "        return most_common_dict\n",
        "\n",
        "\n",
        "    def prepare_text(self, raw_text, normalize=True,\n",
        "                                     remove_punctuation=True,\n",
        "                                     stem=True,\n",
        "                                     lemmatize=True,\n",
        "                                     remove_stop_words=True):\n",
        "        \"\"\"Preprocesses the text with tokenization, case folding, stemming and lemmatization and removing stop words\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        raw_text : str/pandas.core.series.Series\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list\n",
        "            A list of tokens\n",
        "        \"\"\"\n",
        "        if (type(raw_text) == str):\n",
        "            raw_text = pd.DataFrame([raw_text], columns=['text'])['text']\n",
        "\n",
        "        processed_tokens = self.basic_text_preprocess(raw_text, \n",
        "                                                      normalize=normalize,\n",
        "                                                      remove_punctuation=remove_punctuation,\n",
        "                                                      stem=stem,\n",
        "                                                      lemmatize=lemmatize)[0]\n",
        "        \n",
        "        if remove_stop_words:\n",
        "            # remove stop words\n",
        "            processed_tokens = [token for token in processed_tokens if token not in self.stop_words]\n",
        "\n",
        "        return processed_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtyEvTtOeeCJ"
      },
      "source": [
        "## English Pre-Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95jIIFaM73kH"
      },
      "outputs": [],
      "source": [
        "class EnglishPreprocessor(Preprocessor):\n",
        "    def _get_wordnet_pos(self, word):\n",
        "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "        tag_dict = {\"J\": wordnet.ADJ,\n",
        "                  \"N\": wordnet.NOUN,\n",
        "                  \"V\": wordnet.VERB,\n",
        "                  \"R\": wordnet.ADV}\n",
        "\n",
        "        return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "    def _stem_text(self, stemmer, vocab, text):\n",
        "        tokens = []\n",
        "        for word in text:\n",
        "            stemmed = stemmer.stem(word)\n",
        "            if stemmed in vocab:\n",
        "                tokens.append(stemmed)\n",
        "            else:\n",
        "                tokens.append(word)\n",
        "        return tokens\n",
        "\n",
        "    def basic_text_preprocess(self, raw_text, normalize=True,\n",
        "                                             remove_punctuation=True,\n",
        "                                             stem=True,\n",
        "                                             lemmatize=True):\n",
        "        \"\"\"Preprocesses the text with tokenization, case folding, stemming and lemmatization\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        raw_text : df column (pandas.core.series.Series)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        df column\n",
        "            Tokenized pandas dataframe\n",
        "        \"\"\"\n",
        "        dprint(\"raw_text:\", raw_text)\n",
        "                \n",
        "        # normalization\n",
        "        if normalize:\n",
        "            text = raw_text.str.lower()\n",
        "            dprint(\"normalized_text:\", text)\n",
        "        else:\n",
        "            text = raw_text\n",
        "\n",
        "        # tokenization\n",
        "        text_tokens = text.apply(word_tokenize)\n",
        "        dprint(\"after tokenization:\", text_tokens)\n",
        "\n",
        "        # delete punctuation\n",
        "        if remove_punctuation:\n",
        "            for p in self.punctuation:\n",
        "                text_tokens = text_tokens.apply(lambda text: [self._remove_punctuation_from_word(p, word) for word in text])\n",
        "            text_tokens = text_tokens.apply(lambda text: [word for word in text if word != ''])\n",
        "            dprint(\"after deleting punctuation:\", text_tokens)\n",
        "\n",
        "        #stemming\n",
        "        if stem:\n",
        "            stemmer = LancasterStemmer()\n",
        "            vocab = set(words.words())\n",
        "            text_tokens = text_tokens.apply(lambda text: self._stem_text(stemmer, vocab, text))\n",
        "            dprint(\"after stemming:\", text_tokens)\n",
        "\n",
        "        #lemmatizing\n",
        "        if lemmatize:\n",
        "            lemmatizer = WordNetLemmatizer()\n",
        "            text_tokens = text_tokens.apply(lambda text: [lemmatizer.lemmatize(y, self._get_wordnet_pos(y)) for y in text])\n",
        "            dprint(\"after lemmatizing:\", text_tokens)\n",
        "\n",
        "        return text_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "GaWx8T_e8UZR",
        "outputId": "e98c3a74-1189-4958-b492-dfd11ff43827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing title tokens...\n",
            "preprocessing context tokens...\n",
            "preprocessing done.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "english_preprocessor = EnglishPreprocessor(english_txt)\n",
        "english_words_frequencies = english_preprocessor.get_words_frequency()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsRUme9UAYgv",
        "outputId": "581a9356-9043-41b5-d6a0-d841fc48021c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "english_stop_words: {'the': 292311, 'a': 141843, 'to': 140708, 'be': 134696, 'of': 130427, 'and': 119693, 'in': 99626, 'that': 72245, 'on': 59318, 'have': 58270, 'for': 47326, 'it': 46528}\n"
          ]
        }
      ],
      "source": [
        "english_stop_words_limit = 12\n",
        "english_stop_words = english_preprocessor.get_and_set_stop_words(english_words_frequencies, english_stop_words_limit)\n",
        "print(\"english_stop_words:\", english_stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-37CPKI2elcN"
      },
      "source": [
        "## Persian Pre-Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QDL_Nz68PE9"
      },
      "outputs": [],
      "source": [
        "class PersianPreprocessor(Preprocessor):\n",
        "    def basic_text_preprocess(self, raw_text, normalize=True,\n",
        "                                             remove_punctuation=True,\n",
        "                                             stem=True,\n",
        "                                             lemmatize=True):\n",
        "        \"\"\"Preprocesses the text with tokenization, case folding, stemming and lemmatization\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        raw_text : df column (pandas.core.series.Series)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        df column\n",
        "            Tokenized pandas dataframe\n",
        "        \"\"\"\n",
        "\n",
        "        # normalize\n",
        "        if normalize:\n",
        "            normalizer = prv.Normalizer(statistical_space_correction=True)\n",
        "            text = raw_text.apply(normalizer.normalize)\n",
        "            dprint(\"normalized_text:\", text)\n",
        "        else:\n",
        "            text = raw_text\n",
        "\n",
        "        # tokenize\n",
        "        text_tokens = text.apply(word_tokenize)\n",
        "        dprint(\"after tokenization:\", text_tokens)\n",
        "\n",
        "        #delete punctuation\n",
        "        if remove_punctuation:\n",
        "            for p in self.punctuation:\n",
        "                text_tokens = text_tokens.apply(lambda text: [self._remove_punctuation_from_word(p, word) for word in text])\n",
        "            text_tokens = text_tokens.apply(lambda text: [word for word in text if word != ''])\n",
        "            dprint(\"after deleting punctuation:\", text_tokens)\n",
        "\n",
        "        #lemmatizing\n",
        "        if lemmatize:\n",
        "            lemmatizer = Lemmatizer()\n",
        "            text_tokens = text_tokens.apply(\n",
        "                    lambda text: [lemmatizer.lemmatize(w) for w in text])\n",
        "            dprint(\"after lemmatizing:\", text_tokens)\n",
        "\n",
        "        #stemming\n",
        "        if stem:\n",
        "            ps = PersianStemmer()\n",
        "            text_tokens = text_tokens.apply(\n",
        "                    lambda text: [ps.run(w) for w in text])\n",
        "            dprint(\"after stemming:\", text_tokens)\n",
        "\n",
        "        return text_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "rcoDGdY_AfQa",
        "outputId": "c0bb1438-93f1-4845-a9c7-ea86e21d491f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing title tokens...\n",
            "preprocessing context tokens...\n",
            "preprocessing done.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "persian_preprocessor = PersianPreprocessor(farsi_txt)\n",
        "persian_words_frequencies = persian_preprocessor.get_words_frequency()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN3AUAK5Af0C",
        "outputId": "fe296817-5b1c-4151-c4c9-6179e389300f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "persian_stop_words: {'و': 202082, 'در': 191310, 'به': 143895, 'از': 129128, 'که': 86544, 'این': 73642, 'را': 67132, '#است': 57753, 'با': 49885, 'شد#شو': 45540, 'آن': 42506, 'کرد#کن': 41331, 'بود#باش': 34979, 'یک': 34739, 'سال': 32127, 'برای': 25835, 'داشت#دار': 22458, 'او': 21527, 'بر': 18821, 'خود': 17445}\n"
          ]
        }
      ],
      "source": [
        "persian_stop_words_limit = 20\n",
        "persian_stop_words = persian_preprocessor.get_and_set_stop_words(persian_words_frequencies, persian_stop_words_limit)\n",
        "print(\"persian_stop_words:\", persian_stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX3kX5zitEhX"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "توضیحات بخش اول\n",
        "</h2>\n",
        "<p>\n",
        "برای این بخش ما سه کلاس را پیاده‌سازی کردیم. Preprocessor و Persian Preprocessor و English Preprocessor.\n",
        "<p>\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "Preprocessor\n",
        "```\n",
        "</div1>\n",
        "در این کلاس تمامی توابع لازم برای آماده‌سازی متن قرار داده‌شده‌اند و دو کلاس دیگر از این کلاس ارث‌بری می‌کنند. در ادامه توابع آن را توضیح می‌دهیم:\n",
        "<p>\n",
        "<li>\n",
        "_remove_punctuation_from_word :   این تابع علائم نگارشی انگلیسی و فارسی را از متن حذف می‌کند.\n",
        "</li>\n",
        "<li>\n",
        "basic_text_preprocess : از آنجایی که این تابع در بین پیش‌پردازنده فارسی و انگلیسی تفاوت دارد، در اینجا خالی است و هدف از تعریف آن فقط این بوده که هردو کلاس آن را به ارث ببرند.\n",
        "</li>\n",
        "<li>\n",
        "get_words_frequency : در این تابع ابتدا تمامی عنوان‌ها و متن‌ها tokenize می‌شوند و در یک دیتافریم قرار می‌گیرند. پس آز آن تابع فرکانس کلمات را محاسبه کرده و هیستوگرام آن‌ها را می‌کشد. این کار به این منظور است که بتوانیم تصمیم بگیریم که چه تعدادی از کلمات پرتکرار را از متن‌مان حذف کنیم. طبق شکل اینجا برای متن‌های انگلیسی ۱۲ کلمه‌ی اول و برای متن فارسی ۲۰ کلمه‌ی اول را حذف می‌کنیم.\n",
        "</li>\n",
        "<li>\n",
        "get_and_set_stop_words : در این تابع، محدودیت‌ تعداد stopwordها را مشخص می‌کنیم و تابع get_words_frequency را با آن تعداد صدا می‌زنیم.\n",
        "</li>\n",
        "<li>\n",
        "prepare_text : این تابع به این منظور زده‌شده‌است که در صورتی که ورودی‌مان به‌جای آرایه، به شکل یک رشته بود، آن رشته را نیز به صورت دیتافریم در آورده و تابع basic_text_preprocess را روی آن صدا کرده تا عملیات‌‌های لازم را انجام دهد و در انتها هم stopwordها را از متن پاک کند. به این منظور این مرحله را آخر انجام می‌دهیم چون برای پیدا کردن stopword ها نیاز است که روی آن‌ها نیز عملیات basic_prepare_text انجام شود و متن پردازش شود.\n",
        "<p>\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "English Preprocessor\n",
        "```\n",
        "</div1>\n",
        "\n",
        "<p> \n",
        "همانطور که در قسمت قبلی نیز گفتیم، این کلاس یک تابع basic_text_preprocess دارد که در آن به ترتیب عملیات‌های normalization ، tokenization، حذف علائم نگارشی، stemming و lemmization انجام می‌شوند.\n",
        "برای stemming از Lancaster استفاده می‌کنیم. در این مرحله برای \n",
        " دقت بیشتر، درصورتیکه با stem کردن به یک کلمه‌ی معنادار نرسیده‌بودیم، کلمه را بدون تغییر نگه می‌داریم.\n",
        "همچنین برای بخش lemmization، از position tagging  استفاده می‌کنیم. این تابع بررسی می‌کند که نقش هر کلمه در جمله‌مان چیست و با توجه به آن نقش lemmization را انجام می‌دهد.\n",
        "<p> \n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "Persian Preprocessor\n",
        "```\n",
        "</div1>\n",
        "<p> \n",
        "در این کلاس نیز تمامی عملیات‌ها را به ترتیب گفته‌شده در بالا هستند و تنها تفاوت این است که ابتدا lemmization را انجام می‌دهیم و بعد stemming که اینکار برای  بیشتر شدن دقت است. برای stemming از PersianStemmer، برای نرمال‌سازی از parsavir و برای lemmization از hazm استفاده کردیم.\n",
        "</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzpC6pjdSQ6U"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش دوم ( نمایه سازی )\n",
        "</h2>\n",
        "<p>\n",
        "در این بخش پیاده سازی نمایه جایگاهی (Positional) و نمایه Bigram مطلوب است. برای نمایه جایگاهی باید به ازای هر لغت، لیستی از اسناد شامل آن لغت و جایگاه (ها) هر لغت در آن سند داشته باشید و برای نمایه Bigram نیز ترکیب های دوحرفی تمامی کلمات موجود در لغت نامه که این ترکیب در آنها موجود است را ذخیره کنید. این نمایه برای اصلاح پرسمان مورد استفاده قرار خواهد گرفت. نمایه شما باید پویا باشد یعنی با حذف سند از نمایه نیز حذف شود و با اضافه کردن سند یا اسناد در طول اجرای برنامه به نمایه اضافه شود. همچنین بعد از نمایه سازی باید قادر باشید نمایه را در فایلی ذخیره کرده و از آن بخوانید. پویا بودن نمایه و ذخیره سازی آن را برای هردو نوع نمایه در نظر بگیرید.\n",
        "</p>\n",
        "<p>\n",
        "نکات پیاده سازی:\n",
        "</br>\n",
        "برای سادگی پیاده سازی برای هر کارکرد خواسته شده در توضیحات بالا یک تابع پیاده سازی کنید. برای مثال دوتابع برای حذف و اضافه سند به نمایه و توابعی برای ذخیره سازی و بارگزاری نمایه ها و ... در نظر بگیرید.\n",
        "</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8AelVdiGl8J"
      },
      "source": [
        "# Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3bzU_BMnAmB"
      },
      "outputs": [],
      "source": [
        "class TermVocabulary:\n",
        "    def __init__(self, preprocessor, text_df):\n",
        "        self.vocab = {}\n",
        "        self.preprocessor = preprocessor\n",
        "        text_df.apply(lambda row : self.add_new_doc(row['title'] + \" \" + row['text']), axis=1)\n",
        "\n",
        "    def get_tokens(self, text):\n",
        "        return self.preprocessor.prepare_text(text, \n",
        "                                                normalize=True, \n",
        "                                                remove_punctuation=True,\n",
        "                                                lemmatize=False,\n",
        "                                                stem=False,\n",
        "                                                remove_stop_words=False)\n",
        "        \n",
        "    def add_new_doc(self, text):\n",
        "        tokens = self.get_tokens(text)\n",
        "        for token in tokens:\n",
        "            if token not in self.vocab:\n",
        "                self.vocab[token] = 0\n",
        "            self.vocab[token] += 1\n",
        "    \n",
        "    def remove_doc(self, text):\n",
        "        tokens = self.get_tokens(text)\n",
        "        for token in tokens:\n",
        "            if token not in self.vocab:\n",
        "                raise Exception()\n",
        "            self.vocab[token] -= 1\n",
        "            if self.vocab[token] == 0:\n",
        "                del self.vocab[token]\n",
        "\n",
        "    def exist(self, term):\n",
        "        return term in self.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80U6-71knAmC"
      },
      "outputs": [],
      "source": [
        "english_vocab = TermVocabulary(english_preprocessor, english_txt)\n",
        "persian_vocab = TermVocabulary(persian_preprocessor, farsi_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN3svPTSnAmD",
        "outputId": "539fecd1-9a2b-4464-c680-99586646089c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True False\n",
            "False False\n"
          ]
        }
      ],
      "source": [
        "print(english_vocab.exist('hello'), english_vocab.exist('helto'))\n",
        "print(english_vocab.exist('رفتیم'), english_vocab.exist('رقتیم'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SouuYEyle_nW"
      },
      "source": [
        "## Positional Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITS5sgV-Fuz4"
      },
      "outputs": [],
      "source": [
        "class TermInDocPositionalInfo:\n",
        "    def __init__(self):\n",
        "        self.frequency = 0\n",
        "        self.positions = []\n",
        "\n",
        "\n",
        "class TermPositionalInfo:\n",
        "    def __init__(self):\n",
        "        self.total_frequency = 0\n",
        "        self.docs_list = {}\n",
        "\n",
        "\n",
        "class PositionalIndexDictionary():\n",
        "    def __init__(self, preprocessor):\n",
        "        self.terms_dictionary = {}\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def print(self, start=0, end=10):\n",
        "        for term, term_info in list(self.terms_dictionary.items())[start: end]:\n",
        "            print(f\"\\n\\\"{term}\\\":\")\n",
        "            print(f\"total frequency: {term_info.total_frequency}\")\n",
        "            for doc_id, doc_info in term_info.docs_list.items():\n",
        "                print(f\"\\t{doc_id},{doc_info.frequency}\", doc_info.positions)\n",
        "\n",
        "    def add_new_doc(self, doc_id, raw_text):\n",
        "        \"\"\"Add new doc terms to dictionary\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        doc_id: doc_id\n",
        "        raw_text : str\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        terms = self.preprocessor.prepare_text(raw_text)\n",
        "        for pos, term in enumerate(terms):\n",
        "            # add term to dictionary if not exist\n",
        "            if term not in self.terms_dictionary:\n",
        "                self.terms_dictionary[term] = TermPositionalInfo()\n",
        "\n",
        "            # add doc to term info dictionary if not exist\n",
        "            if doc_id not in self.terms_dictionary[term].docs_list:\n",
        "                self.terms_dictionary[term].docs_list[doc_id] = TermInDocPositionalInfo(\n",
        "                )\n",
        "\n",
        "            # update term statistic\n",
        "            term_info = self.terms_dictionary[term]\n",
        "            term_info.total_frequency += 1\n",
        "            term_info.docs_list[doc_id].frequency += 1\n",
        "\n",
        "            # add position to list\n",
        "            term_info.docs_list[doc_id].positions.append(pos)\n",
        "\n",
        "    def remove_doc(self, doc_id, raw_text):\n",
        "        \"\"\"Remove doc terms from dictionary\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        doc_id: doc_id\n",
        "        raw_text : str\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        terms = prepare_text(raw_text)\n",
        "        for pos, term in enumerate(terms):\n",
        "            if term not in self.terms_dictionary:\n",
        "                raise Exception()\n",
        "\n",
        "            if doc_id not in self.terms_dictionary[term].docs_list:\n",
        "                raise Exception()\n",
        "\n",
        "            # update term statistic\n",
        "            term_info = self.terms_dictionary[term]\n",
        "            term_info.total_frequency -= 1\n",
        "            term_info.docs_list[doc_id].frequency -= 1\n",
        "\n",
        "            # remove position from list\n",
        "            term_info.docs_list[doc_id].positions.remove(pos)\n",
        "\n",
        "    def get_gaps(self):\n",
        "        docs = {}\n",
        "        gaps = {}\n",
        "        for term, term_info in self.terms_dictionary.items():\n",
        "            docs[term] = []\n",
        "            for doc_id, doc_info in term_info.docs_list.items():\n",
        "                docs[term].append(doc_id)\n",
        "            docs[term] = sorted(docs[term])\n",
        "            docs[term].insert(0, 0)\n",
        "            \n",
        "            gaps[term] = [docs[term][i]-docs[term][i-1]\n",
        "                          for i in range(1, len(docs[term]))]\n",
        "        return gaps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrfvjKvqnAmE"
      },
      "outputs": [],
      "source": [
        "def create_positional_index(preprocessor, text_df):\n",
        "    \"\"\"Creates the bigram index for spell correction\"\"\"\n",
        "    b = PositionalIndexDictionary(preprocessor)\n",
        "    text_df.apply(lambda row : b.add_new_doc(row.name, row['title'] + \" \" + row['text']), axis=1)\n",
        "    return b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYlUq_esnAmF"
      },
      "outputs": [],
      "source": [
        "english_positional_index = create_positional_index(english_preprocessor, english_txt)\n",
        "english_positional_index.print(start=0, end=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "w8-qOzF4nAmG",
        "outputId": "5426f182-fea2-420a-a552-95540547cbc2"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0fe6be25889c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpersian_positional_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_positional_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersian_preprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfarsi_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpersian_positional_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-3638c7676390>\u001b[0m in \u001b[0;36mcreate_positional_index\u001b[0;34m(preprocessor, text_df)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Creates the bigram index for spell correction\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalIndexDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtext_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_new_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7551\u001b[0m         )\n\u001b[0;32m-> 7552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-3638c7676390>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Creates the bigram index for spell correction\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalIndexDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtext_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_new_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-3251c6cf1c19>\u001b[0m in \u001b[0;36madd_new_doc\u001b[0;34m(self, doc_id, raw_text)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \"\"\"\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# add term to dictionary if not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-35a53582e17d>\u001b[0m in \u001b[0;36mprepare_text\u001b[0;34m(self, raw_text, normalize, remove_punctuation, stem, lemmatize, remove_stop_words)\u001b[0m\n\u001b[1;32m    103\u001b[0m                                                       \u001b[0mremove_punctuation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_punctuation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                                                       \u001b[0mstem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                                                       lemmatize=lemmatize)[0]\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_stop_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b29622255a43>\u001b[0m in \u001b[0;36mbasic_text_preprocess\u001b[0;34m(self, raw_text, normalize, remove_punctuation, stem, lemmatize)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistical_space_correction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mdprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"normalized_text:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parsivar/normalizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, half_space_char, statistical_space_correction, date_normalizing_needed, pinglish_conversion_needed, train_file_path, token_merger_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_merger_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_merger_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_merger_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_merger_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_merger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_merger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parsivar/data_helper.py\u001b[0m in \u001b[0;36mload_var\u001b[0;34m(self, load_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/probability.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mCounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Cached number of samples in this FreqDist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/probability.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    651\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "persian_positional_index = create_positional_index(persian_preprocessor, farsi_txt)\n",
        "persian_positional_index.print(start=0, end=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex-H88vafFKq"
      },
      "source": [
        "## Bigram Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuy2i0BNhvkl"
      },
      "outputs": [],
      "source": [
        "class BigramInfo:\n",
        "    def __init__(self):\n",
        "        self.terms = {}\n",
        "\n",
        "\n",
        "class BigramIndexDictionary():\n",
        "    def __init__(self, preprocessor, must_prepare_text=False):\n",
        "        self.bigram_dictionary = {}\n",
        "        self.preprocessor = preprocessor\n",
        "        self.must_prepare_text = must_prepare_text\n",
        "\n",
        "    @property\n",
        "    def flat_bigram_dictionary(self):\n",
        "        flat_dict = {key: [term for term in val.terms.keys()] for key, val in self.bigram_dictionary.items()}\n",
        "        return flat_dict\n",
        "\n",
        "    def print(self, start=0, end=10):\n",
        "        for bigram, info in list(self.bigram_dictionary.items())[start: end]:\n",
        "            print(f\"\\n\\\"{bigram}\\\":\")\n",
        "            for term, freq in info.terms.items():\n",
        "                print(f\"({term},{freq})\", end=\" \")\n",
        "\n",
        "                \n",
        "    def get_tokens(self, text):\n",
        "        return self.preprocessor.prepare_text(text, \n",
        "                                                normalize=True, \n",
        "                                                remove_punctuation=True,\n",
        "                                                lemmatize=False,\n",
        "                                                stem=False,\n",
        "                                                remove_stop_words=False)\n",
        "    \n",
        "    def add_new_doc(self, raw_text):\n",
        "        \"\"\"Add new doc terms to dictionary\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        raw_text : str\n",
        "\n",
        "        \"\"\"\n",
        "        terms = self.get_tokens(raw_text)\n",
        "            \n",
        "        for term in terms:\n",
        "            augmented_term = \"$\" + term + \"$\"\n",
        "            for i in range(len(augmented_term) - 1):\n",
        "                bigram = augmented_term[i:i + 2]\n",
        "\n",
        "                # add bigram to dictionary if not exist\n",
        "                if bigram not in self.bigram_dictionary:\n",
        "                    self.bigram_dictionary[bigram] = BigramInfo()\n",
        "\n",
        "                # add term to bigram list if not exist\n",
        "                if term not in self.bigram_dictionary[bigram].terms:\n",
        "                    self.bigram_dictionary[bigram].terms[term] = 0\n",
        "\n",
        "                # update term statistic\n",
        "                self.bigram_dictionary[bigram].terms[term] += 1\n",
        "\n",
        "                # print(bigram, term)\n",
        "                # self.print(start=0, end=2)\n",
        "\n",
        "        \n",
        "    def remove_doc(self, raw_text):\n",
        "        \"\"\"Remove doc terms from dictionary\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        raw_text : str\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        terms = self.get_tokens(raw_text)\n",
        "        \n",
        "        for term in terms:\n",
        "            augmented_term = \"$\" + term + \"$\"\n",
        "            for i in range(len(augmented_term) - 1):\n",
        "                bigram = augmented_term[i:i + 2]\n",
        "\n",
        "                if bigram not in self.bigram_dictionary:\n",
        "                    raise Exception()\n",
        "\n",
        "                # add term to bigram list if not exist\n",
        "                if term not in self.bigram_dictionary[bigram].terms:\n",
        "                    raise Exception()\n",
        "\n",
        "                # update term statistic\n",
        "                self.bigram_dictionary[bigram].terms[term] -= 1\n",
        "                if self.bigram_dictionary[bigram].terms[term] == 0:\n",
        "                    del self.bigram_dictionary[bigram].terms[term]\n",
        "\n",
        "    def get_gaps(self):\n",
        "        docs = {}\n",
        "        gaps = {}\n",
        "        for term, term_info in self.bigram_dictionary.items():\n",
        "            docs[term] = set()\n",
        "            for vocab, doc_id in term_info.terms.items():\n",
        "                docs[term].add(doc_id)\n",
        "            docs[term] = list(sorted(docs[term]))\n",
        "            docs[term].insert(0, 0)\n",
        "            \n",
        "            gaps[term] = [docs[term][i]-docs[term][i-1]\n",
        "                          for i in range(1, len(docs[term]))]\n",
        "        return gaps\n",
        "\n",
        "\n",
        "    def get_bigrams(self, term):\n",
        "        augmented_term = \"$\" + ''.join(self.get_tokens(term)) + \"$\"\n",
        "        dprint(term, augmented_term)\n",
        "        bigrams = [augmented_term[i:i + 2] for i in range(len(augmented_term) - 1)]\n",
        "        return bigrams\n",
        "      \n",
        "    def get_bigrams_count(self, term):\n",
        "        return len(self.get_bigrams(term))\n",
        "    \n",
        "    def get_terms_with_common_bigrams(self, query, minimum_common_bigrams = 1):\n",
        "        query_bigrams = self.get_bigrams(query)\n",
        "        terms = {}\n",
        "        for bigram in query_bigrams:\n",
        "            if bigram not in self.bigram_dictionary:\n",
        "                continue\n",
        "            bigram_term_list = self.bigram_dictionary[bigram].terms\n",
        "            for term in bigram_term_list:\n",
        "                if term not in terms:\n",
        "                    terms[term] = 0\n",
        "                terms[term] += 1\n",
        "\n",
        "        return {term:count for term,count in terms.items() if count >= minimum_common_bigrams}\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ze8ljO0nnAmI"
      },
      "outputs": [],
      "source": [
        "def create_bigram_index(preprocessor, text_df):\n",
        "    \"\"\"Creates the bigram index for spell correction\"\"\"\n",
        "    b = BigramIndexDictionary(preprocessor)\n",
        "    text_df.apply(lambda row : b.add_new_doc(row['title'] + \" \" + row['text']), axis=1)\n",
        "\n",
        "    return b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Snk8wC9snAmJ",
        "outputId": "e48bae46-e571-4158-a7b8-ac8c6c1b0042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\"$y\":\n",
            "(you,204) (york,51) (your,79) (years,65) (yvoe,1) (yet,27) (young,16) (year,40) (yelled,1) (yusor,1) (yale,6) (yearold,11) (yales,2) (youngsters,1) (yeah,3) (youtube,15) (yes,12) (yahoos,1) (youre,13) (yourselves,1) (yourself,6) (yue,3) (youve,2) (ypg,3) (youll,5) (york—in,1) (yemen,4) (years,1) (yuval,1) (yellenled,1) (yields,1) (yellen,2) (y,3) (year—and,1) (yank,1) (yeti,1) (youngster,1) (yorks,2) (ying,4) (yang,4) (yuan,1) (younger,1) (yard,5) (youth,3) (yusufiy,1) (yearwill,1) (yorktowashington,1) (york daily,1) (yorkbased,1) (yazidis,17) (yazidi,10) (yukawa,2) (yaakov,1) (yemenis,1) (yield,1) (yezidi,1) (youd,1) (yesterday,1) (yelling,2) (yesmen,1) \n",
            "\"yo\":\n",
            "(you,204) (york,51) (everyone,24) (your,79) (cokhyouusrfs,1) (young,16) (anyone,13) (youngsters,1) (youtube,15) (ayotte,11) (ayottes,1) (youre,13) (beyond…,1) (yourselves,1) (mayor,7) (hall mayor,1) (yourself,6) (beyond,9) (youve,2) (youll,5) (york—in,1) (youngster,1) (yorks,2) (younger,1) ( you,1) (youth,3) (fightersyou,1) (yorktowashington,1) (york daily,1) (mayors,3) (yorkbased,1) (tokyo,2) (youd,1) (wyoming,1) (payouts,1) (crayon,1) (layoffs,1) \n",
            "\"ou\":\n",
            "(you,204) (journalism,3) (around,34) (ought,3) (hour,13) (would,139) (wouldnt,10) (foundation,9) (spouting,1) (outdone,2) (house,96) (thought,10) (countless,3) (your,79) (out,144) (mysterious,4) (enough,30) (could,94) (about,203) (country,67) (outcome,8) (without,35) (throughout,22) (wound,3) (through,44) (numerous,3) (delicious,1) (course,22) (announced,12) (aboutface,1) (previously,9) (couldnt,7) (courage,1) (roughly,3) (doubts,1) (our,119) (shouldnt,3) (outspoken,1) (contentious,1) (account,13) (cokhyouusrfs,1) (preposterous,1) (couldve,2) (young,16) (sought,6) (outsiders,3) (religious,9) (foundational,1) (sounds,5) (pounding,1) (outside,16) (courtyard,6) (group,38) (ground,19) (shouting,1) (countries,10) (righteous,2) (found,38) (scout,1) (shoulder,2) (countrys,4) (proud,3) (tremendously,1) (founding,2) (soul,4) (should,57) (countrymen,1) (couple,4) (seriously,4) (thousands,12) (although,7) (youngsters,1) (though,38) (tremendous,5) (matthews about,1) (scarborough,1) (fought,4) (nouri,1) (encountered,1) (hangzhou,1) (zhou,1) (youtube,15) (outraged,3) (accountability,3) (underground,2) (counterpart,2) (missouri,2) (hours,8) (hardfought,1) (flatout,1) (serious,12) (forour,1) (discounts,1) (previous,15) (doubt,7) (pronounced,1) (rough,2) (resources,6) (loud,1) (sound,3) (south,22) (rigorously,1) (famous,3) (counterparts,2) (tough,9) (double,2) (court,26) (enormous,2) (encouraged,1) (council,3) (southern,7) (amount,2) (doubled,3) (houses,4) (turnout,5) (outnumber,1) (brought,8) (trouble,3) (encounters,1) (rouhani,1) (counting,1) (encouragement,1) (dangerous,6) (count,2) (ourselves,2) (ours,1) (youre,13) (odious,1) (touch,5) (yourselves,1) (borough,6) (routinely,1) (touted,1) (sounding,2) (councilwoman,2) (boroughs,1) (accountable,1) (four,15) (outcry,1) (rounds,2) (unanimously,4) (outline,1) (dubious,1) (rabblerousers,1) (groups,30) (yourself,6) (mouths,1) (sources,6) (allout,1) (mount,7) (bound,3) (counsel,2) (counter,4) (unbound,1) (outright,2) (soundly,1) (outrage,1) (trounces,1) (denouncing,1) (youve,2) (accounts,12) (outsized,1) (southfront,1) (ramouseh,1) (countryside,1) (nour,2) (linkedgroups,1) (outlets,1) (miraculous,1) (consciousness,2) (cofounded,1) (youll,5) (tsatsouline,1) (simultaneously,1) (encourages,3) (rapacious,1) (discouraged,1) (obviously,2) (breakthrough,4) (encourage,4) (vicious,1) (wouldbe,1) (source,4) (troubling,3) (anxious,1) (tour,2) (shouts,2) (furious,2) (outdid,1) (coups,1) (journal,2) (houthis,1) (jour,1) (household,1) (bailout,2) (lousy,1) (amounted,2) (outweigh,1) (touches,2) (hazardous,1) (tout,2) (journalist,3) (journalists,4) (turnaround,1) (toughguy,1) (ambitious,2) (groundwork,1) (youngster,1) (coup,2) (voucherizing,1) (courted,2) (counselor,1) (advantageous,1) (cautious,1) (heterogeneous,1) (outcomes,1) (founder,2) (boundaries,1) (discourse,1) (notorious,2) (sarsour,2) (humorous,1) (anonymous,2) (though…and,1) (enough…,1) (stout,2) (outmaneuvered,1) (louisiana,1) (younger,1) (sioux,1) ( you,1) (we should,1) (round,1) (surrounding,2) (unanimous,2) (courtesy,1) (outpost,1) (freedomoutpost,1) (precious,2) (troublesome,2) (hourlong,1) (outdoor,1) (couplehundred,1) (sounded,1) (youth,3) (louima,1) (fourthgeneration,1) (shoulders,1) (announcement,2) (grounded,1) (froth about,1) (famously,2) (counterproductive,1) (our board,1) (threehour,1) (counterintelligence,1) (bought,1) (twohour,1) (recounted,1) (ridiculous,1) (rumours,1) (mysteriously,2) (fightersyou,1) (outreach,1) (houston,1) (the groundwork his,1) (recounting,1) (journey,1) (outperformed,1) (toughest,2) (courting,1) (courageous,2) (honourable,1) (behaviour,1) (outrageous,2) (outofcontrol,1) (background,2) (rabblerousing,1) (loudly,1) (nourished,1) (clout,1) (outsider,1) (counted,1) (poured,2) (courts,1) (louis,1) (coupled,1) (unambiguous,1) (outward,1) (ouster,2) (outspokenly,1) (county,3) (councilman,2) (councils,1) (ingenious,1) (conscientious,1) (saviour,1) (labour,1) (thorough,1) (scoundrel,3) (foul,1) (thoughts,1) (douma,2) (wounded,11) (southeastern,2) (outskirts,2) (mourns,2) (ashmoun,1) (mourners,1) (redouble,1) (toufic,1) (outoftouch,2) (infamous,1) (youd,1) (obvious,1) (rapturous,1) (bounded,1) (zealous,1) (encouraging,1) (undoubtedly,1) (countercoup,6) (intercourse,2) (and counterterrorism,1) (kouachi,3) (mourad,1) (shootout,1) (routine,1) (continuously,2) (selfjourney,1) (suspicious,1) (mizzou,1) (payouts,1) (spontaneously,1) (spontaneous,2) (tourism,1) (ridiculously,1) (tourists,1) (outsells,1) (courageously,2) (accountants,2) (doublebarrel,1) (announces,2) (mounting,1) (thoughtful,1) (outlaws,1) (outdated,1) (clouds,1) (outofpocket,1) (fourthplace,1) (countered,1) (tougher,1) \n",
            "\"u$\":\n",
            "(you,204) (bureau,2) (u,80) (netanyahu,1) (hangzhou,1) (zhou,1) (menu,1) (sununu,3) (plateau,1) (noneu,3) (eu,5) (hindu,5) (du,1) ( you,1) (americachicagothu,1) (fightersyou,1) (and u,1) (russianu,1) (aclu,1) (mizzou,1) (landrieu,1) (chu,1) \n",
            "\"$c\":\n",
            "(can,125) (center,29) (clinton,205) (coma,1) (cnn,23) (comey,20) (circulated,1) (currently,6) (clintons,49) (continue,15) (credibility,2) (covert,1) (compared,6) (column,3) (calling,11) (comeys,1) (claiming,3) (carville,1) (coordinating,2) (conspiracy,3) (countless,3) (charge,9) (classified,6) (cable,4) (conspiracies,1) (coy,1) (computer,5) (cunning,1) (criminal,12) (corrected,2) (claim,12) (could,94) (campaign,125) (candidate,42) (confident,5) (country,67) (control,35) (clintonworld,2) (claimed,21) (cover,10) (crime,13) (corruption,10) (come,24) (careers,1) (closing,4) (cycle,4) (changed,16) (committed,11) (cowardice,2) (course,22) (chilly,1) (covytt,1) (comwcvscg4a5i,1) (couldnt,7) (chances,4) (cravenly,1) (career,6) (clearly,5) (conservative,37) (came,22) (colleagues,9) (conviction,2) (cards,1) (collapsed,3) (close,15) (comment,24) (courage,1) (criticism,6) (conclusion,5) (childhood,5) (commitments,5) (city,35) (conference,8) (crystal,1) (clear,18) (commitment,3) (candidates,35) (columnist,2) (contentious,1) (cokhyouusrfs,1) (couldve,2) (convention,37) (circulate,1) (closeness,1) (credited,2) (call,27) (cartwright,1) (clinch,4) (contested,6) (cruz,76) (contests,7) (caucuses,11) (cheer,2) (capture,2) (closer,3) (central,5) (change,21) (christians,13) (chose,2) (child,6) (class,14) (chants,1) (capital,8) (corridor,2) (classroom,2) (chanting,2) (collars,1) (courtyard,6) (commanded,1) (classmates,5) (countries,10) (capitulate,1) (chant,1) (certainly,11) (coming,18) (charred,3) (closed,10) (clutching,1) (crowd,10) (civilians,5) (commotion,1) (camel,2) (compliment,1) (chest,2) (cub,1) (countrys,4) (camera,2) (cried,3) (ceremony,3) (carpet,1) (ceremonial,1) (caused,11) (chief,11) (completed,1) (creation,4) (childish,1) (complex,6) (chapel,2) (carolina,13) (chord,1) (contacted,3) (costs,8) (confront,2) (committee,36) (challenge,12) (communities,10) (community,21) (clash,4) (civilizations,1) (countrymen,1) (consider,6) (common,14) (caught,7) (closest,1) (college,12) (chat,3) (couple,4) (cheek,1) (care,36) (corner,5) (called,28) (chilling,1) (cant,20) (crimes,7) (case,22) (czech,1) (children,16) (czechoslovakia,1) (childrens,2) (carrying,8) (check,11) (commanderinchief,4) (claims,10) (certain,9) (china,12) (cuba,6) (cherrypicked,2) (commander,3) (cited,6) (cavuto,3) (concern,9) (chris,6) (comments,18) (criticize,3) (combat,4) (condoleezza,1) (closely,6) (cubas,3) (castro,1) (chinas,2) (constituted,2) (chancellor,2) (checker,1) (chairman,6) (completely,5) (changes,7) (current,14) (card,3) (choose,8) (compete,1) (circumstances,3) (centers,2) (cannot,7) (choice,9) (creating,4) (complete,10) (criticized,6) (channel,11) (creative,1) (concerns,12) (concessions,3) (crucial,3) (comes,16) (converted,1) (centrifuges,4) (caps,1) (characterized,1) (condition,2) (closeddoor,1) (created,8) (centrifuge,1) (constrain,1) (canceled,1) (counterpart,2) (contributed,3) (click,8) (cedar,2) (crowd one,1) (carried,5) (chanted,1) (chelsea,2) (charismatic,1) (cigi,1) (campaigns,15) (considered,4) (crisscrossing,1) (colorado,7) (caucus,6) (cleveland,4) (congressional,12) (convoluted,1) (contest,10) (cruzsupporting,1) (camp,2) (cobb,1) (copyright,1) (connection,5) (credit,3) (com,19) (content,6) (companies,9) (confidential,2) (congress,65) (challenger,2) (competitive,2) (corporate,9) (consensus,4) (california,7) (committees,7) (catholic,2) (congresswoman,1) (connections,2) (cooperation,4) (confidence,5) (cooperative,1) (cosponsors,2) (commonality,1) (critical,6) (compromise,4) (combating,2) (cites,3) (chair,7) (cantwell,1) (chance,7) (clam,1) (chowder,1) (collins,3) (constitute,3) (collaboration,1) (cite,2) (catalyst,2) (collaborative,2) (catch,1) (collegial,1) (counterparts,2) (ceo,3) (cook,1) (court,26) (culture,5) (citizens,8) (commission,2) (comeback,2) (council,3) (championed,2) (chili,1) (classic,3) (cracked,3) (champ,1) (crown,1) (cultural,6) (combined,2) (charting,1) (continues,6) (contrast,2) (chambers,2) (controlled,6) (cognizant,1) (conversations,2) (colleges,1) (crew,4) (circle,1) (corkers,2) (contemplating,1) (counting,1) (corker,2) (corkermenendez,2) (cosponsor,1) (crippling,1) (comprehensive,3) (cuts,3) (combative,1) (count,2) (chuck,1) (charges,6) (chart,5) (charts,2) (consistently,6) (condos,1) (condemned,3) (contrary,2) (comfortable,6) (christian,11) (committing,1) (controversy,2) (culinary,1) (cornyn,1) (catholics,1) (covers,3) (conduct,3) (contributor,2) (coast,3) (contain,2) (carry,5) (cops,2) (citys,2) (coalition,14) (controversial,3) (commissioner,2) (cruzs,8) (chorus,2) (councilwoman,2) (capitol,8) (christmas,5) (cry,3) (comfortably,1) (conflict,5) (compel,1) (coaching,1) (craving,1) (code,7) (corral,1) (critics,5) (challenging,3) (conservatives,7) (clashes,12) (clarify,1) (challenges,5) (cost,4) (ceiling,1) (chosen,3) (colleague,2) (clues,1) (checked,2) (crowded,3) (construction,1) (concerned,7) (comparative,1) (compelling,2) (celebrity,5) (capita,1) (coincides,1) (computers,5) (connected,3) (continuing,3) (commentator,1) (conscience,3) (candidacy,6) (cnns,2) (casts,2) (counsel,2) (counter,4) (curly,2) (cowrote,1) (consultant,1) (contending,1) (chatter,1) (concerted,2) (commanding,1) (coal,2) (considering,3) (changing,5) (charged,2) (curiel,2) (chaos,4) (conclusive,1) (casinos,1) (cast,2) (cocksure,1) (consequential,1) (corey,2) (chaotic,2) (costa,2) (capacity,3) (clearest,1) (corners,1) (crises,6) (covered,2) (concentrated,1) (collapse,2) (commanders,4) (competing,2) (countryside,1) (captured,2) (coordination,1) (coordinated,3) (confirm,3) (carly,3) (crushed,1) (comprehend,1) (comprehension,1) (cell,7) (cosmos,1) (cytocosmos,2) (celestial,1) (cross,4) (complexity,1) (cellular,3) (cosmologies,1) (cosmology,1) (consciousness,2) (claudia,1) (christine,1) (cofounded,1) (concept,3) (connective,3) (correct,2) (context,4) (cases,6) (chamber,3) (commerce,3) (confined,1) (cease,1) (carl,4) (crave,1) (century,1) (cryin,2) (corrupting,1) (c,22) (centered,1) (civil,10) (concentrating,1) (chuckles,2) (converse,1) (conversation,4) (coopted,1) (compares,1) (consideration,2) (causes,5) (concluded,1) (choosing,4) (casting,2) (commissions,1) (contributing,1) (congressman,2) (carlos,2) (cameras,1) (contained,3) (containing,2) (congressmans,1) (caption,2) (cato,1) (cesspool,1) (copresidency,1) (coups,1) (colombia,1) (confrontation,2) (circumvent,1) (constitutional,3) (chooses,1) (cia,3) (cooperating,2) (confrontationally,1) (chicago,8) (claritypress,1) (comlendmaniii,1) (cuttingedge,1) (craft,2) (contenders,2) (considers,2) (credible,6) (census,1) (core,6) (challenged,4) (conceded,1) (citing,2) (clean,3) (cut,6) (continued,6) (challenges ,1) (cities,16) (consolidating,1) (calls,12) (conclusions,1) (chimed,2) (cme,1) (clients,1) (crater,2) (constructed,1) (cobjgcfo0du5,1) (comnrmqnbw5uk,1) (con,2) (coverage,1) (composed,1) (coral,1) (crude,2) (cushing,2) (chemical,2) (carol,1) (colonial,2) (colonials,1) (company,8) (concocted,1) (cultivate,1) (casualties,2) (chiefs,2) (carafano,1) (cubicle,1) (confessed,2) (crooked,2) (coup,2) (commrpulso1oe,1) (consistent,3) (coalitions,4) (crosspartisan,2) (conflicts,2) (culmination,3) (competition,11) (contradictions,5) (corrupt,9) (conservatism,1) (coasts,1) (centralized,8) (campaigning,4) (classes,1) (constituency,2) (considerably,1) (contribution,2) (convince,3) (crisis,4) (crony,4) (capitalists,2) (cold,1) (crazy,4) (confirmed,8) (capitalist,1) (courted,2) (counselor,1) (cleared,3) (concentrations,2) (consisted,1) (crosscut,1) (cannon,3) (considerable,1) (chafed,1) (crosscutting,1) (crossparty,2) (cautious,1) (committeedriven,2) (corporatewall,1) (cause,5) (centrists,1) (cartoon,3) (cartoons,4) (cue,1) (clashed,2) (compare,3) (civilized,3) (coonfield,4) (communication,1) (contorted,2) (civilization,2) (create,10) (collective,2) (christianity,3) (craziness,1) (complicated,4) (crops,2) (capable,1) (checks,2) (combine,1) (citea,1) (citedcite,1) (comname,1) (character,4) (confusing,2) (charlie,11) (chinese,4) (craig,2) (contract,1) (comex,1) (cot,4) (contracts,4) (commercials,4) (commercial,1) (certainty,1) (consolidation,2) (comnews,1) (cantalupo,2) (coffee,3) (complained,2) (colorados,1) (charles,1) (concerning,2) (cbs,3) (clip,2) (cellphones,1) (comparison,1) (conducted,2) (columbia,2) (consent,3) (circumstantial,1) (courtesy,1) (clothesline,1) (confederates,1) (certify,2) (copies,2) (categories,1) (contributions,1) (cuban,6) (couplehundred,1) (chased,1) (cares,1) (correctness,1) (caja,1) (car,3) (confirming,1) (coffin,3) (confronting,1) (confirmation,3) (convictions,1) (custody,1) (church,7) (cheerleading,2) (cheerleader,1) (connect,2) (cozy,1) (cartel,2) (controlling,2) (capitalism,4) (counterproductive,1) (constituent,1) (corporation,1) (communications,2) (communicate,1) (corporations,5) (contributors,3) (columns,1) (checking,1) (conclude,2) (contact,2) (club,1) (counterintelligence,1) (centre,1) (concretely,1) (celebrated,1) (canine,1) (conflicting,1) (carter,2) (cowering,1) (clubs,1) (colon,1) (chadwick,1) (controls,1) (correctly,1) (controlhillary,1) (candidatesthey,1) (choicethey,1) (classupper,1) (classthose,1) (crowdunless,1) (communist,1) (cochairman,2) (considered friendly to,1) (columba,1) (commissionergeorge,1) (courting,1) (command,5) (courageous,1) (convicting,1) (communism,3) (confronted,1) (campaigned,4) (caucusgoers,1) (consolidate,1) (collectively,1) (convinced,1) (cage,1) (clout,1) (carson,8) (condensed,1) (clarity,2) (calendar,1) (criteria,2) (counted,1) (capi­tal­ize,1) (cnbc,1) (christie,5) (christies,1) (cash,1) (compelled,1) (courts,1) (crosschecking,1) (canfield,1) (cigarillos,1) (convenience,4) (corroborated,1) (corroborate,1) (coupled,1) (corroborates,1) (charging,3) (crawford,1) (cochairs,3) (criticisms,1) (canova,1) (credentials — are,1) (confused,1) (coherent,1) (cochairmanship,1) (connecticut,2) (county,3) (channels,1) (collaborate,1) (councilman,2) (culpeper,1) (conditions,1) (color,1) (contractors,2) (councils,1) (copresident,1) (citybycity,1) (credits,1) (comply,1) (compromises,1) (compensation,2) (conscientious,1) (cop,4) (carroll,1) (careful,1) (corbin,1) (chips,1) (charlatan,1) (crack,1) (charlatans,1) (cretin,1) (clown,2) (crazier,1) (constitutes,1) (cries,3) (crossing,4) (celebrates,2) (cundi,2) (cemetery,3) (captive,2) (celebrate,4) (condolences,1) (citizen,1) (crucifixions,2) (checkpoints,1) (capturing,2) (crashed,1) (concert,1) (circulating,1) (commend,1) (carefully,1) (cardinal,1) (carrier,1) (collar,1) (cuomo,1) (complications,1) (ceded,1) (cain,1) (celebrities,2) (consequence,2) (circuit,1) (citizenship,1) (crossroads,1) (cool,1) (crowds,1) (cringed,1) (centuries,1) (countercoup,3) (contacts,1) (cazeneuve,1) (caricatured,1) (chérif,3) (convicted,1) (caricatures,1) (collider,3) (cern,1) (colliders,1) (continuously,2) (caring,1) (continuum,1) (creepy,1) (colonialism,1) (canada,2) (che,1) (contol,1) (criminals,1) (climate,1) (circumcision,1) (classmate,1) (cons,1) (cowboy,2) (cubeshaped,1) (copy,1) (customers,1) (cartoonists,1) (cubaus,1) (cubans,1) (certificate,1) (cope,1) (clocks,1) (czar,1) (crayon,1) (choices,4) (carney,5) (confuse,1) (convert,1) (cancel,1) (crimea,1) (conquest,1) (courageously,1) (cube,2) (cancels,1) (charity,1) (coverup,1) (calories,1) (chupacabras,1) (chavez,1) (corpse,1) (cliffs,1) (ceilings,1) (canonize,1) (criticizing,1) (constitution,1) (charms,1) (chimney,1) (claus,1) (clouds,1) (contraceptives,1) (congratulates,1) (chicagostyle,1) (cheap,1) (circumcisions,1) (choom,1) (cancer,1) (cure,1) (chu,1) (conservation,1) (codenamed,1) (ceostyle,1) (ceos,3) (commute,1) (compensate,1) (cubanamerican,1) (credentials,1) (countered,1) (constitutionalist,1) "
          ]
        }
      ],
      "source": [
        "english_bigram_index = create_bigram_index(english_preprocessor, english_txt)\n",
        "english_bigram_index.print(start=0, end=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNb_GS6CnAmJ",
        "outputId": "8d417a4b-4aa0-4c3d-e3e0-b47ac57e1ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\"$ر\":\n",
            "(رفتار,22) (روی,77) (رفته,1) (روانشناسی,7) (را,613) (روانی,3) (رفتارهای,2) (رفتاری,4) (رویه,2) (رفتارها,1) (روشی,2) (رفتارگرایی,2) (روانکاوی,1) (روز,14) (رازهای,1) (روابط,4) (روش,4) (رقابت,7) (راتسهیل,1) (راتقلید,1) (راه,36) (رضا,3) (رغبت,1) (راضی‌کننده,1) (رفتارشان,1) (رتبه,6) (رسیدن,4) (رفیع,1) (راحت‌تر‌باکسی‌دعواکنید,1) (روش‌های,2) (راحتی,3) (رضایت,4) (رشتهٔ,1) (روستاهای,9) (رفت,11) (رشته,8) (رومیان,1) (راست,13) (رابطه,19) (راست‌همنهشتی,4) (رابطه‌formula,1) (رده‌ای,1) (ریانووستی,2) (روسیه,6) (ریا,2) (روسی,3) (روزنامه‌نگاران,2) (روزنامه‌های,3) (راننده,2) (رسید,16) (رساندن,3) (روایت,2) (روزنامه,5) (راستی,1) (روزنامه‌نگاری,2) (رسانده‌اند,1) (رفسنجانی,3) (روزنامه‌ها,2) (رنسانس,1) (رنگرز,3) (روزی,2) (رنگ‌آمیزی,1) (رسانایی,1) (روستایی,6) (روستا,24) (راهبردی,1) (روحانیت,3) (روستای,32) (روایات,1) (روح,2) (رهایی,1) (رژیم,5) (رجال,2) (رحیم‌خبازباشی,1) (رویدادهای,1) (ریاست,10) (راستا,2) (رحلت,2) (رسیدهاست,6) (رونق,2) (روحانیان,1) (رضاشاه,1) (روحانیانی,1) (رسیدهبود,3) (رسمی,3) (ریاست‌جمهوری,3) (رئیس‌جمهور,10) (ربط,2) (رها,4) (رفتن,2) (ردیف,1) (رفته‌اند,1) (ریموند‌چندلر,1) (ریچارد,7) (روزنامهٔ,1) (رکورد,4) (رابطه‌اش,1) (رمان,9) (رمانش,1) (رمان‌,1) (راوی,1) (رقص,4) (رویایی,1) (رابطهٔ,1) (راستای,8) (روزمره,1) (راست‌گرد‌,1) (رادار,1) (ریاضی,1) (رحم,1) (روغن,1) (رهبر,1) (راهی,4) (روی‌شبکهٔ‌IP,1) (رایانه‌ای,1) (رمزگذاری,4) (روش‌ها,1) (رگی,1) (رمزگذار,1) (راهنماهای,1) (رسیده,1) (رواج,1) (رو,7) (ردیابی,1) (رمزگذاری‌IPsec,1) (رتبه‌بندی,2) (راه‌گزینی,1) (رسانه‌ای,1) (رادیوی,4) (رادیو,1) (رادیوهای,3) (رشد,7) (رهنمود,3) (روبرو,2) (رسانندگان,1) (رساننده,2) (رسانهٔ,1) (رسانه‌,1) (رضوی,3) (ریلی,1) (روریلی,1) (رمانش‌شبح,1) (رمان‌نویسی,1) (رمانی,1) (راز,2) (رسالت,2) (رعبی,1) (ریخت,1) (رحمه‌للعالمین,1) (رسول,2) (ربیع‌الاول,1) (رخ,5) (راجع,2) (روم,7) (رقیب,2) (رومی,1) (رادویانی,1) (رویانا‌رویانا,1) (رویان,2) (رویانا,3) (رویال‌هیلتون,2) (رستم,4) (راسته‌ها,2) (راسته‌های,2) (راسته,4) (رنگها,1) (روحانی,8) (رایگان,1) (رضایی,1) (رقم,3) (رکورددار,1) (روزهای,3) (رویداد,2) (راه‌سازی,1) (ریاست‌جمهوری‌اش,1) (راهبری,1) (رکود,1) (ربود,1) (رخدادها,1) (رسانه‌های,1) (راداشته,1) (راه‌های,2) (رایج,1) (رسیدگی,2) (رابطه‌ای,1) (رازی,2) (رای,5) (رای‌کاتبی,1) (رویگردانی,1) (رفاه,1) (رودخانه,2) (رودخانه‌های,2) (روستای‌وشته‌,1) (روستای‌ورکش‌,2) (روستای‌میراش‌,1) (روستای‌جزن‌,1) (روستای‌کولج‌,1) (روستای‌گلینک‌,1) (رئیس,5) (روشنفکران,3) (رخداد,1) (روزه‌اش,1) (رنگ,4) (رد,1) (روشن‌گری,1) (روستاییان,2) (روشنگری,1) (روحانیون,10) (رابه,1) (راهپیمایی,1) (رجعت,1) (رهبری,3) (روبسپیر,2) (رسته,1) (رعیت,1) (رسیدند,1) (رفع,1) (رسما,1) (رادیکالیسم,1) (رسمیت,1) (رود,1) (راین,1) (راس,1) (رشته‌ی,1) (رینولدز,1) (راولپندی,1) (روزگاری,1) (روزگار,1) (راازهما‌مالینی,1) (ریشی‌کاپور‌و‌دیویا‌بهاراتی,1) (روبه‌رو,1) (راجو‌بن‌گایا‌جنتلمن,1) (راجو‌آقا,1) (روشن,2) (راکی,1) (رگه‌های,1) (رمانتیک,2) (راجو‌بن‌گایاجنتلمن‌ویس‌باس,1) (رام,1) (رزمی,1) (راهول,1) (ریشه‌های,1) (ردیف‌جزو,1) (راج,3) (رب,2) (رنج,1) (رضوان,1) (ریسک‌ها,1) (روهیت‌شتی‌درمقابل‌دیپیکا‌پادوکن,1) (رکوردهای,2) (راهول‌دولاکیا,1) (راوان,1) (ریشه‌واژه‌بیسموت,1) (رنگین‌کمانی,1) (رنگی,2) (رمان‌های,1) (رولینگ,1) (ریورساید,1) (روایت‌شوخ‌طبعانه,1) (رشوه‌خوار,1) (روشن‌تر,1) (رودیان‌بنابر,1) (رابط,11) (رندرینگ‌دوبعدی,1) (رندرینگ,2) (رایانه,1) (رابطی,1) (رابط‌های,1) (رطوبت,1) \n",
            "\"رف\":\n",
            "(رفتار,22) (فرو‌رفته,1) (رفته,1) (رفتارهای,2) (رفتاری,4) (رفتارها,1) (رفتارگرایی,2) (‌رفتارگرایی,1) (اعلامیه‌رفتارگرا,1) (‌رفتار,1) (حرفهای,1) (صرف,3) (گرفت,31) (گرفته‌شود,1) (رفتارشان,1) (رفیع,1) (رفت,11) (گرفتار,1) (گرفته,8) (رفسنجانی,3) (می‌رفتند,1) (می‌رفت,4) (فراگرفته,1) (عرفی,1) (طرف,3) (پذیرفت,2) (گرفتهبود,2) (عرفانی,1) (شگرفی,1) (پذیرفتهمی‌شود,1) (رفتن,2) (پذیرفته,2) (پرفروش‌شده,1) (رفته‌اند,1) (تاثیرگرفته,1) (گرفتهاست,3) (واسدا‌رفت,1) (گرفتند,2) (حرفه‌ای,3) (گرفتهنشدهاست,1) (تصرف,2) (اندازه‌گرفت,1) (گرفتهمی‌شود,4) (نظرگرفت,1) (ظرفیت,2) (گرفتن,7) (طرفین,2) (پیشرفت,2) (گرفتهخواهدشد,1) (مصرف‌کنندگان,3) (مصرف‌کننده,2) (معرفی,9) (متعارف,1) (گرفتهشدهاست,3) (پذیرفتن,1) (بی‌طرفی,1) (گرفتهمی‌شوند,1) (‌سامانه‌تعرفهٔ,1) (مصرفی,2) (مصرف,2) (شرفهااللّه‌تعالی,1) (شرفنامه‌منیری‌,1) (ازطرف‌مشرق‌روحانیات,1) (ظرفیتی,3) (می‌گرفته,1) (خواهدگرفت,1) (طرفداران,1) (ترفندهایی,1) (معرف,2) (رفاه,1) (برفگیری,1) (شرف,1) (آذرفر,1) (فرا‌گرفته‌اند,1) (رفع,1) (مصارف,2) (پذیرفتهشد,1) (طرفدارانش,1) (پرطرفدارترین,1) (بمبئی‌رفت,1) (پرفروش,13) (فیر‌گرفت,1) (درفیلم‌مایا‌ممساب,1) (پرفروش‌ترین,7) (اودرفیلم,1) (درفیلم,4) (درزندگی‌حرفه‌ایش‌یادمی‌کند,1) (شگرف‌ترین,1) (خان‌درفیلم‌جدیدیاش,1) (فیلم‌پرفروش‌سال,1) (جراحی‌آرتروسکوپی‌قرارگرفت,1) (طرفدار,1) (پرفروشترین,1) (کاررفته,1) (بوپرنورفین,1) (مورفین,1) (گرفتهمی‌شد,1) (برگرفته,1) (ظرف,1) (نام‌رورند‌اسموت‌رفت,1) (می‌گرفت,1) (نپذیرفت,1) (می‌گرفتند,1) (حرف,3) (گرفتهشد,1) (در‌نظرگرفتن‌اینکه,1) \n",
            "\"فت\":\n",
            "(رفتار,22) (فرو‌رفته,1) (رفته,1) (رفتارهای,2) (رفتاری,4) (یافته,12) (رفتارها,1) (رفتارگرایی,2) (‌رفتارگرایی,1) (یافتهبود,3) (اعلامیه‌رفتارگرا,1) (‌رفتار,1) (گفت,14) (گرفت,31) (گرفته‌شود,1) (رفتارشان,1) (مخالفت,2) (عقب‌افتاده,1) (می‌افتد,4) (رفت,11) (هفتگی,1) (گرفتار,1) (گفتهٔ,2) (گفته,7) (یافت,22) (گفتند,1) (می‌گفت,2) (گفتهبود,3) (گرفته,8) (هفتم,2) (می‌رفتند,1) (می‌رفت,4) (فراگرفته,1) (گفتگو,1) (پذیرفت,2) (ناگفته,1) (گرفتهبود,2) (دریافته,1) (نهفته,3) (پذیرفتهمی‌شود,1) (گفتار,1) (یافته‌اند,4) (رفتن,2) (پذیرفته,2) (رفته‌اند,1) (دریافت,23) (تاثیرگرفته,1) (گرفتهاست,3) (واسدا‌رفت,1) (گرفتند,2) (گرفتهنشدهاست,1) (دفتر,4) (گفتن,1) (اندازه‌گرفت,1) (گرفتهمی‌شود,4) (جفت,4) (فتق,1) (وهفتصد,1) (در‌دلفت‌,1) (هفت,3) (دلفت,1) (نظرگرفت,1) (یافتهاست,3) (گرفتن,7) (نهفتگی,2) (دریافت‌کننده,1) (جفت‌شدگی,1) (مسافت‌های,1) (پیشرفت,2) (گرفتهخواهدشد,1) (مسافت,3) (دریافت‌کنندگان,1) (دفتری,1) (گرفتهشدهاست,3) (پذیرفتن,1) (گرفتهمی‌شوند,1) (افتادهاست,1) (معروفترین,1) (افتتاح,1) (هفت‌اورنگ,2) (صفت,1) (گفته‌اند,2) (هفت‌قلزم‌,1) (شتافتند,1) (فتح,1) (می‌گرفته,1) (ابوالفتح,1) (فتحعلی,2) (خفته,1) (بافتن,2) (خواهدگرفت,1) (نمی‌یافت,1) (بافتهبود,1) (می‌شکافت,1) (نفت,7) (گفتهمی‌شود,3) (نفتی,4) (هفته,2) (گفته‌منتقدینش,1) (افت,1) (دست‌نیافتنی,1) (تفتازانی,5) (تفتازان,1) (‌تفتازانی,2) (هفتمین,2) (فرا‌گرفته‌اند,1) (آشفتگی‌های,1) (افتاد,1) (یافتند,1) (گفتهشد,1) (نیفتاد,1) (پذیرفتهشد,1) (افتخارات,1) (افتخار,1) (بمبئی‌رفت,1) (فیر‌گرفت,1) (شگفت‌انگیز,1) (شگفت‌انگیزاست‌,1) (بافتا,1) (شرافتمندانه,1) (جراحی‌آرتروسکوپی‌قرارگرفت,1) (کاررفته,1) (افتخاری,1) (هفتصد,1) (گرفتهمی‌شد,1) (برگرفته,1) (لطافت,1) (دفتردار,2) (دلشیفته,1) (نام‌رورند‌اسموت‌رفت,1) (می‌گرفت,1) (هفته‌نامه,1) (نپذیرفت,1) (داروفروش‌شیفت,1) (گفتهنشد,1) (می‌گرفتند,1) (می‌افتند,2) (گرفتهشد,1) (در‌نظرگرفتن‌اینکه,1) (بافت,1) (اثافت,1) \n",
            "\"تا\":\n",
            "(رفتار,22) (رفتارهای,2) (رفتاری,4) (تا,109) (تابع,5) (رفتارها,1) (رفتارگرایی,2) (گشتالت,1) (‌رفتارگرایی,1) (اعلامیه‌رفتارگرا,1) (تاثیر,8) (‌رفتار,1) (پرتاب,1) (کودکستان,1) (دوستانهٔ,1) (دوستانه,2) (استادانه‌اند,1) (رفتارشان,1) (برایتان,1) (زندگیتان,1) (عقب‌افتاده,1) (قبرستانی,1) (روستاهای,9) (استان,36) (دهستان,41) (شهرستان,47) (دبیرستان,2) (گرفتار,1) (ایتالیا,2) (تاکید,3) (بلفیکه‌بلفیکه‌دهستانی,1) (ارمنستان,2) (گرجستان,1) (تاسیس,3) (گلستان,3) (نهایتا,1) (اصالتا,1) (ساختار,7) (تاج‌آباد,2) (روستایی,6) (روستا,24) (دهستان‌منتظریه,1) (پارسنت‌پارسنت‌دهستانی,1) (استان‌های,3) (تاریخ,22) (تاریخی,7) (روستای,32) (استادان,6) (استادی,1) (کتاب,20) (کودتای,6) (کودتا,2) (تابستان,4) (راستا,2) (تازه‌ای,1) (تاکنون,9) (خودمختاری,2) (گفتار,1) (تازهٔ,1) (تامین,9) (کتاب‌ها,1) (داستان‌های,22) (داستان,22) (کوتاه,12) (تاثیرگرفته,1) (دستاوردها,1) (گوستاو,1) (فیودور‌داستایوفسکی,1) (تاثیرات,1) (کتابی,2) (داستانی,3) (استاد,5) (بالستان,2) (راستای,8) (کریستال,2) (ولتاژ,1) (یکتا,1) (بازتاب,2) (بتادین,1) (جنگ‌هشتادساله‌علیه‌سلطهٔ,1) (پروتستانها,1) (دست‌بالتازار‌گرارد,1) (فرستاد,2) (دیجیتال,3) (دیجیتالی,2) (دوستان,3) (تاخیر,11) (تاخیردار,1) (‌تاخیرهای,1) (تاخیرها,1) (فرستاده,1) (کشورتان,2) (فیزیکی‌تان,1) (تامین‌کنندهٔ‌VoIP,1) (استاندارد,11) (نسبتا,5) (لپ‌تاپ,1) (سرتاسر,2) (شبکهٔ‌دیجیتال,1) (دیتای‌خلاصه‌شدهٔ‌مجزاست,1) (تازه,4) (سپتامبر,10) (افتادهاست,1) (چندتایی,1) (انگلستان,4) (هکتار,1) (افتتاح,1) (اتاق,5) (تا‌بنات‌نعش,1) (تاج,1) (عادیان‌فرستاد,1) (کوهستان‌بکر,1) (تا‌اینکه,2) (تاختند,1) (شتافتند,1) (باستان,4) (تاخت‌و,1) (دهستان‌المذبح,1) (عربستان,1) (سیستانی,1) (کتابت,4) (ساختارهای,2) (تایی,1) (همتاسازی,3) (تاکسیدرمی,1) (پنج‌ستارهٔ,1) (‌کاپیتال‌بولتز,1) (کتابخانه,5) (پراگرسیو‌متال‌پراگرسیو‌متال,2) (هوی‌متال,3) (ساختاری,2) (سبک‌پروگرسیو‌دث‌متال‌و‌پروگرسیو‌متال‌و,2) (پروگرسیو‌متال,1) (تائید,1) (عمدتا,2) (تاوریس,1) (به‌تازگی,2) (پیتام,1) (استانداری,1) (مجموعه‌فرهنگستانها,1) (بوستان,4) (نتایج,1) (تفتازانی,5) (تفتازان,1) (‌تفتازانی,2) (استادش,1) (متاخران,1) (پاکستان,5) (‌مانیوئتا‌دهستانی,2) (دراین‌دهستان,1) (زمستان,3) (دهستان‌زیاران,2) (دهستان‌پائین,1) (کوهستانی,1) (زمستانها,1) (یاستانی,1) (باستانی,3) (قبرستان,4) (بادامستان,1) (روستای‌وشته‌,1) (روستای‌ورکش‌,2) (روستای‌میراش‌,1) (روستای‌جزن‌,1) (روستای‌کولج‌,1) (روستای‌گلینک‌,1) (‌قبرستان,2) (‌قرستان‌رونا,1) (تایید,3) (تاب,1) (تاجش,1) (دادستان,1) (مارتینس‌مارتینس‌دهستانی,1) (کتاپانگ,1) (شهرستان‌های,1) (باستان‌شناسی,1) (افغانستان,1) (تاجیکستان,2) (تات,3) (تاریخچه,1) (درختان,2) (دیکتاتوری,2) (تاریخ‌دانان,2) (روستاییان,2) (اتاژنرو,1) (ممتاز,1) (افتاد,1) (تالار,1) (نیفتاد,1) (تالیران,1) (تادیه,1) (هشتاد,1) (تابستان‌,4) (هندوستان,4) (ستارهٔ,1) (کاپیتان,1) (دوستانش,1) (ستاره,3) (سوپراستار,1) (آدیتا‌چو,1) (هندوستانی,4) (مجلهٔ‌تایم,1) (دراقتباس‌مانی‌کال‌ازکتاب,1) (داستایوفسکی‌ظاهرشد,1) (ساختهٔ‌کتان,1) (مهتا,1) (مامتاکولکارنی,1) (ایندیاتایمزموویز,1) (باستان‌شناس,1) (ستایش,4) (فیلم‌همکارآمیتاب‌باچان,1) (بافتا,1) (سوشمیتاسن‌و,1) (آمریتارائو,1) (کنار‌پریتی‌زینتا,1) (آدیتیاچوپرادرنقش‌ویرپرتاب,1) (ستایش‌آمیز,1) (متاسفانه,2) (ستایش‌برانگیزبود,1) (بازی‌آمیتاب‌باچان‌درسال,1) (بازی‌آمیتاب‌باچان,1) (‌تاران‌آدارش,1) (تایمز,2) (تاریخ‌هنداست,1) (‌کال‌تاحدی‌درگیشه,1) (جوایز‌استار‌اسکرین,1) (کوتاه‌ا,1) (کتاب‌های,2) (داستان‌جلدکاغذی,1) (دبستانی,1) (تاثیرگذار,2) (پرستار,1) (گیتار,1) (داستان‌هایی,1) (دیکتاتوری‌های,1) (بیمارستان,2) (می‌فرستاد,1) (داستان‌ها,4) (گورستان,1) (داستان‌هایش,2) (شتاب,1) (کتابخانهٔ,4) (استانداردی,1) (کتابخانه‌های,1) (کتابخانه‌هایی,1) (تاریک,1) (زمستان‌,1) (مستان,1) (وتاریخ‌نویس,1) \n",
            "\"ار\":\n",
            "(رفتار,22) (ارگانیسم,1) (کاربرد,5) (دارد,91) (بیماری‌های,1) (رفتارهای,2) (رفتاری,4) (همواره,7) (نظاره‌گر,1) (کارهای,5) (قرار,65) (کار,74) (بسیار,31) (موارد,6) (رفتارها,1) (دربارهٔ,12) (رفتارگرایی,2) (بنیان‌گذاری,1) (‌رفتارگرایی,1) (بنیان‌گذار,1) (انتشار,12) (اعلامیه‌رفتارگرا,1) (جای‌گذارد,1) (بزهکاران,1) (جنایتکاران,1) (‌رفتار,1) (ناروا,1) (وارد,21) (ندارد,13) (می‌تواندصدمه‌واردکند,1) (مهارت,2) (ارتباطهای,1) (آشکار,2) (دارند,36) (باحرارت,1) (عبارتست,1) (همجواری,1) (ارتباط,44) (بسیاری,46) (دشواری,1) (بیلیارد,1) (فداکاری,1) (کاری,8) (اظهار,2) (دارای,23) (ارتباطات,10) (مهارتهای,2) (سازگار‌تر,1) (کارها,5) (ارزشهای,1) (بار,22) (انکار,1) (برقرار,4) (می‌سپارند,2) (ارزش,7) (کارایی,1) (رفتارشان,1) (کنار,9) (بگذارید,1) (استثمار‌مردانند,1) (داریوش,2) (سفارش‌دهندهٔ,1) (کارگر,3) (شهرداری,3) (اجبار,3) (خدمتکار,1) (فرار,8) (باریکه,1) (باریکه‌هایی,1) (فارسی,18) (همکاری,12) (پاریس,14) (مشارکت,2) (سبحانی‌دربارهٔ‌ازدواجش,1) (گرفتار,1) (خارج,22) (ارزی,19) (داریم,4) (نماد‌گذاری,2) (عبارت,6) (تعاریف,2) (بیارجمند,4) (سبزوار,2) (سرشماری,11) (آمار,11) (خبرگزاری,4) (اخبار,4) (ارمنستان,2) (داراست,2) (کاربران,4) (‌سرمهماندار,1) (‌کار,1) (مهمانداری,1) (سرمهماندار,1) (روزنامه‌نگاران,2) (بکار,1) (تجاری,18) (پاسداران,5) (وزارت,13) (کارکنانش,1) (مهماندار,1) (بردارد,1) (نگهداری,5) (اصرار,1) (اشاره,17) (اقتدارگرایان,2) (میهماندار,1) (روزنامه‌نگاری,2) (جنگ‌افزار,2) (اروپا,11) (احضار,3) (وادار,1) (لومباردی,1) (آثار,19) (اردیبهشت,4) (ساختار,7) (گذار,2) (خانوار,11) (پارسنت‌پارسنت‌دهستانی,2) (تاریخ,22) (درختزارهای,1) (تاریخی,7) (شمار,5) (دیار,2) (عبارتند,6) (ارتش,5) (مبارزان,1) (افکار,3) (دیداری,1) (دیدارها,1) (ارادتمندان,1) (تکرار,4) (گزارش‌های,5) (استقرار,4) (گزارش,7) (دیدار,2) (درباره,2) (آثارش,2) (زیارت,1) (مبارزات,2) (اسارت,2) (مدارس,2) (اینباره,1) (پرکار,1) (یاری,4) (ارتقائ‌رتبه,1) (جوار,2) (مارکز,1) (خریداری,1) (بارها,3) (دوره‌والری‌ژیسکار‌دستن,1) (دوباره,5) (خارجی,11) (برگزار,2) (خودمختاری,2) (بازدارد,1) (ارادهٔ,2) (اختیار,9) (گفتار,1) (کردار,1) (مبارزه‌های,1) (برخوردار,5) (هزاران,2) (استعمار,2) (ارائه,10) (فشار,4) (آزار,1) (عبارت‌هایی,1) (بارز,1) (آزاری,2) (چهارراه,2) (لاله‌زار,1) (هاروکی‌موراکامی‌هاروکی‌موراکامی‌زادهٔ,2) (ریچارد,7) (گاردین,1) (پایدار,4) (باروری,1) (بازارگان,1) (اروپایی,2) (چارلز,2) (اداره,10) (بچه‌دار,1) (دوندهٔ‌ماراتن,1) (اولتراماراتن,1) (اطراف‌دریاچهٔ‌ساروما,1) (بسپار,2) (گوش‌بسپار‌,1) (باره,1) (همکار,2) (هاروارد,4) (ارام,1) (پلاریزاسیون,2) (بردار,2) (ندارند,1) (پلاریزه,1) (رادار,1) (هارمونیک,1) (ادرار,1) (دستکاری,1) (هزار,21) (پایه‌گذاری,1) (دست‌بالتازار‌گرارد,2) (دیوار,2) (بارهٔ,2) (انصاری,4) (مقداری,2) (سبزواری,1) (بهاری,2) (عبدالغفار,1) (ارایه,1) (شماره‌گیری,5) (شماره‌های,4) (شمارهٔ,6) (نرم‌افزاری,8) (نرم‌افزار,7) (ارسال,9) (سخت‌افزار,3) (ناکارآمد,1) (شارژ,2) (رمزگذاری,4) (کارگزاران,2) (همکاران,1) (یکپارچه‌شوند,1) (سازوکار,1) (ناپایداری,3) (مدار,3) (ماهواره‌ای,2) (ماهواره‌های,1) (تاخیردار,1) (سازگاری,1) (دیوارهای,7) (برقراری,3) (NATS‌متقارن,1) (نشان‌دار,1) (کارکردی,1) (توسعهٔ‌کارایی,1) (پارازیت‌,1) (گزارش‌خلاصهٔ‌SIP‌RTCP,1) (رمزگذار,1) (وارده,3) (هدف‌گذاری,2) (اضطراری,4) (شمارهٔ‌اورژانس,1) (سیار,9) (استاندارد,11) (می‌گذارند,1) (شماره‌ای,2) (ناسازگار,1) (سخت‌افزاری,2) (میلیاردها,1) (دلار,11) (سرمایه‌گذاری,1) (بازار,22) (ارتباطی,2) (ارث,3) (یک‌شبکهٔ‌سلولار,1) (انتظار,4) (مستعار,7) (کاربردهای,2) (بارکد,1) (انبارها,1) (چهار,9) (دیواری,1) (کارمند,2) (ابزارهای,2) (مقدار,8) (انحصاری,2) (کدگذاری,1) (رمزگذاری‌IPsec,1) (کارگران,1) (کارت‌های,1) (یک‌شمارهٔ‌PSTN,1) (کلاهبرداری,1) (بازمی‌گذارد,1) (کاربر,1) (بازاریابی,2) (ارزان‌تر,1) (‌عبارت,1) (عبارت‌های,1) (شماره,8) (برندارد,1) (تکراری,1) (اختیاری,2) (خودکار,4) (کارکرد,1) (هشداردهنده,1) (متعارف,1) (سلولار,1) (دوبارهٔ,1) (اروپای,2) (ارتقا,1) (ارزنده,1) (ارتقای,2) (به‌وسیلهٔ‌تکرارکننده‌های,1) (تکرارکننده‌ها,2) (تکرارکنندهٔ,1) (تکرارکننده‌های,2) (تکرارکننده,1) (دیدارگران‌آنلاین,1) (انحصارگران,1) (کارائیب,1) (بازارهای,2) (بازاری,2) (اظهارنظر,1) (قرارداد,4) (ارائه‌شده,5) (کاربردی,1) (واگذار,7) (تجارت,2) (واگذاری,6) (هزینه‌دار,1) (تهیه‌کننده‌شمارهٔ,1) (سربار,1) (عنوان‌گذاری,1) (سربار‌سرآیند‌بسته,1) (شنیداری,1) (سربار‌سرآیند‌بستهٔ,1) (حاجیلار,2) (چایپاره,1) (هکتار,1) (دارا,1) (اراضی,4) (برخورداری,1) (پدیدار,1) (خبرنگار,2) (کارگردان,4) (فارغ‌التحصیل,2) (سردمداران,1) (خبرنگاری,1) (ادگار,1) (ادراری,1) (منتهی‌الارب‌,1) (سمارا,1) (پارسی,1) (اشارتست,1) (چاره‌ندیدند,1) (سنگریزه‌هارا,1) (بارهای,1) (چهارمحال‌بختیاری‌قراردارد,4) (لاران,1) (طایفه‌بختیاروند‌بلیوند,1) (چهاردانگه‌بخش,1) (مارس,4) (عبارتی,1) (سپهسالار,1) (پیکار,2) (اردوگاه,1) (مبارزه,2) (بگذارند,1) (سالار,1) (سیاست‌مدار,1) (و‌همپیمان‌ژولیوس‌سزار,1) (سیاست‌مداران,1) (نامدار,2) (سزار,1) (سردار,1) (ژولیوس‌سزار,1) (فارسال,1) (اردشیر‌بن‌دیلمسار‌نجمی,2) (اسکار,4) (پیکسار,1) (ابتکارش,1) (ساختارهای,2) (چهاروجهی,1) (نارس,1) (سزارین,1) (نارسایی,1) (نامگذاری,3) (دانمارکی,2) (دانمارک,1) (پارسیان,3) (پنج‌ستارهٔ,1) (پارک,2) (ارسیز,1) (بهره‌برداری,1) (برگزاری,3) (هتل‌داری,1) (قارون,1) (فیلمبرداری,4) (ویزاردز‌واشنگتن‌ویزاردز,2) (واشنگتن‌ویزارد,1) (دربار,2) (فارس,3) (نگارخانه,1) (مزار,1) (قاجار,6) (کاروانسراهای,3) (مقارن,1) (کاروانسرای,1) (معماری,2) (چهار‌سوقها,1) (گهواره‌ای,1) (بکارگیری,2) (کاشیکاری,1) (قاجاری‌درسطوح,1) (ارکان,1) (خواستگاران,5) (وفادار,1) (خواستگارانش,1) (پارچه,2) (وفاداری,1) (اختصار‌Prog‌Metal,1) (ساختاری,2) (‌ارین,1) (ارین,1) (هارمونیزه,1) (طرفداران,1) (برخوردار‌اند,1) (شعار,3) (یارانه‌ها,5) (شعارها,1) (زمامداری,2) (کارشناسان,17) (میلیارد,14) (ارائه‌کرد,2) (یارانه,2) (خانوارهای,2) (خانوارهااطلاعات,1) (مدارک,1) (یکبار,2) (خانوارها,1) (واریز,2) (اظهارات,3) (آمارهای,5) (آماری,2) (ارز,3) (وارداتی,1) (مهار,3) (رکورددار,1) (ارقامی,1) (واردات,1) (دلارهای,1) (دچار,3) (بیماری,8) (عوارض,2) (گزارشی,1) (جارو,1) (اعتبار,3) (قرارگاه,3) (اینکار,1) (وزارتخانه‌های,2) (به‌کارگیری,1) (سرشار,3) (ادارات,2) (جاری,1) (ارزش‌های,1) (سارکید,1) (برخودار,1) (شارمندی,1) (دارایی,1) (اجباری,2) (فریبکاری,1) (فریبکار,1) (اراده,1) (بیدار,1) (می‌انگارد,1) (حصارها,1) (دارید,1) (ارزیابی,2) (معیار,8) (کارشناس,5) (باروند,1) (دپارتمان‌ها,1) (گزارش‌دهند,1) (کارشان,1) (بگذارد,1) (کارشناسی,2) (مهارت‌های,1) (‌کارشناسانی,1) (کارشناس‌های,1) (برون‌سپاری,1) (برونسپاری,1) (هم‌بار,1) (ارتباط‌گستر,1) (پارسا,1) (استانداری,1) (مقدارش,1) (کشف‌الاسرار,1) (عده‌الابرار,1) (به‌خارجیه‌و,1) (ارضی,1) (سرمایه‌داری,2) (وزارتخانه,1) (پارچه‌آبادی,1) (ارتفاع,4) (کلاردشت,1) (چندار,1) (کوه‌ارزنگ,1) (باریکان,4) (باریکان‌روخانه‌و‌فلکبا‌روخانه,1) (بهار,1) (بارندگی,2) (حرارت,2) (دهستان‌زیاران,2) (کناره,1) (بهره‌برداری‌میباشد,1) (غار,4) (‌غار,1) (اردکان,1) (ارژنگ,2) (سیاستمدار,1) (دستیار,1) (چهارمین,3) (عطاریان,1) (دستیار‌ویژه,3) (اظهاراتی,1) (خبرگزاری‌ها,1) (مارتینس‌مارتینس‌دهستانی,2) (باریکی,1) (تنگه‌قراردارند,2) (قرارند,1) (سارگون,2) (پارت,1) (استقراری,1) (ماندگاری,1) (ماندگار,1) (تاریخچه,1) (پارت‌ها,1) (زیارتگاهی,1) (بارش,1) (باران,1) (برده‌داری,1) (استثمار,1) (می‌شمارند,1) (ناپلئون‌بناپارت,3) (مارکسیستی,1) (تاریخ‌دانان,2) (نارضایتی,2) (گاهشمار,1) (دارایی‌های,1) (وارن‌دستگیرشده,1) (گناهکار,1) (ماری‌آنتوانت,1) (یارانش,1) (دیرکتوار,3) (‌ناپلئون‌بناپارت,1) (ناچار,1) (کناره‌گیری,1) (پارلمان,2) (نظارت‌های,1) (گارد,2) (چهارم,3) (بیگاری,1) (پاریسی,1) (تالار,1) (مصارف,2) (مخارج,1) (نظارت,1) (افتخارات,1) (کاریزماتیک,1) (برومر‌دیرکتوار,1) (ادوارد‌میلز‌پورسل‌ادوارد‌میلز‌پورسل,2) (کارنامهٔ,1) (ستارهٔ,1) (ورزشکار,1) (روزگاری,1) (ستاره,3) (روزگار,1) (کارگردانی,12) (سوپراستار,1) (افتخار,1) (طرفدارانش,1) (پرطرفدارترین,1) (ادارهٔ,1) (ریشی‌کاپور‌و‌دیویا‌بهاراتی,1) (مادام‌بواری,1) (انتقادی‌وتجاری‌درسال,1) (‌کاران,1) (مامتاکولکارنی,1) (باری,1) (خارج‌ازهند‌وبهترین,1) (آیشواریا,1) (فیلم‌همکارآمیتاب‌باچان,1) (باکارن,1) (مدوری‌دیکشیت‌وآیشواریا,1) (هم‌تومهاره‌صنم,1) (آمریتارائو,1) (زارا,1) (کنار‌پریتی‌زینتا,1) (نقش‌مهان‌بارگاوا,1) (کارن,2) (ساران,1) (‌تاران‌آدارش,2) (درخارج,1) (سفارشی,2) (جراحی‌آرتروسکوپی‌قرارگرفت,1) (مبتلابه‌سندروم‌اسپارگر,1) (بیماران,1) (اسپارگر,1) (کومار,1) (انوشکاشارما,1) (زارادرسال,1) (تاریخ‌هنداست,1) (مبارک,1) (طرفدار,1) (وتجاری,1) (کاچهار,1) (کاران,1) (هستم‌کاران,1) (بعدی‌کاران,1) (کاررفته,1) (جشنوارهٔ,1) (جشنواره,1) (جوایز‌استار‌اسکرین,1) (بالیوود‌مووی‌اواردز,1) (آپسارا,1) (افتخاری,1) (داروی,1) (اروپائی,1) (کارخانه,1) (حرارتی,1) (دارویی,1) (پایدارترین,1) (بخار,1) (ماری,1) (اولینا‌ماریا,1) (دفتردار,2) (داروخانه,2) (داروسازی,2) (گرته‌برداری,1) (تاثیرگذار,2) (پرستار,1) (خانواده‌هارلز,1) (داروساز,1) (تحویلدار,2) (گیتار,1) (هیل‌سیتی‌کوارتت,1) (خواستگاری,1) (نام‌مارگارت‌وورث‌پورتر,2) (کارش,1) (نقشه‌برداری,1) (بکسار‌شماره,2) (فرماندار,2) (مارگارت,8) (بیمار,1) (داروفروش‌شیفت,1) (بیمارستان,2) (چهارده,1) (سارا,3) (کارولینای,2) (فشاری,1) (می‌خوارگی,1) (ناراحتی,1) (سوگواری,1) (کارمندان,1) (رشوه‌خوار,1) (چارچوب,1) (ابتکارات,1) (وارْدْ‌مک‌آلیستر,1) (چهارصد,1) (آمارگیر,1) (عبارت‌اند,1) (نام‌مستعاری‌که,1) (استانداردی,1) (نرم‌افزارهای,1) (ارائه‌دهند,1) (معماری‌Khronos‌Group,1) (ابزار,1) (موزاییک‌کاری,1) (سخت‌افزارهای,1) (کاربری,1) (تاریک,1) (چشمهٔ‌آقادار,1) (وتاریخ‌نویس,1) "
          ]
        }
      ],
      "source": [
        "persian_bigram_index = create_bigram_index(persian_preprocessor, farsi_txt)\n",
        "persian_bigram_index.print(start=0, end=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJY5EdIjDH9M"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "توضیحات بخش دوم\n",
        "</h2>\n",
        "<p>\n",
        "این بخش به دو قسمت Positional Indexو Bigram Index تقسیم‌ می‌شود که هرکدام را جداگانه توضیح می‌دهیم. به‌جز این دو مورد یک کلاس TermVocabulary هم داریم که در ادامه معرفی می‌کنیم.\n",
        "<p>\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "TermVocabulary Index \n",
        "```\n",
        "</div1>\n",
        "<p>\n",
        "این کلاس لیستی از لغات را بدون stemming و lemmization و با استفاده از نوع پیش‌پردازنده‌ای که دریافت می‌کند، نگه می‌دارد. از خروجی این کلاس در قسمت bigram index استفاده می‌کنیم.\n",
        "<p>\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "Positional Index \n",
        "```\n",
        "</div1>\n",
        "<p>\n",
        "در اینجا کلاس اصلی ما PositionalIndexDictionary است که این کلاس یک پیش‌پردازنده و یک لغت‌نامه دارد.  پیش‌پردازنده را می‌توان از بین فارسی و انگلیسی انتخاب کرد.\n",
        "در لغت‌نامه به ازای هر term غیرتکراری یک نمونه از کلاس TermPositionalInfo ساخته می‌شود .\n",
        "کلاس TermPositionalInfo نیز درخود فرکانس کلی یک term را همراه با یک نمونه‌ی از کلاس TermInDocPositionalInfo نگه می‌دارد.\n",
        "<p>\n",
        "در نهایت کلاس TermInDocPositionalInfo شماره‌ی داک‌هایی که آن term در آن تکرار شده را همراه با فرکانس تکرار در هر سند و موقعیت‌اش ذخیره می‌کند.\n",
        "<p>\n",
        "کلاس PositionalIndexDictionary همچنین دو تابع برای اضافه و حذف کردن سندها و یک تابع برای به ‌دست آوردن gapها دارد که این تابع برای بخش سوم به کار می‌آید.\n",
        "<p>\n",
        "در تابع add_new_doc، ابتدا متن را پردازش می‌کنیم. پس از آن به ازای هر term ای که در آن سند قرار دارد، ابتدا چک می‌کنیم که از قبل در لغت‌نامه‌مان بوده‌است یا نه. در صورتیکه نبوده باشد برای آن دیکشنری‌ای می‌سازیم که شامل فرکانس کلی، شماره‌ی سندها تعداد تکرار در هر سند و موقعیت term در هر داک باشد.\n",
        "اما در صورتیکه از قبل در لغت‌نامه وجود داشته، یک دیکشنری از نوع TermInDocPositionalInfo  برای آن درست می‌کنیم. فرکانس کلی کلمه را نیز آپدیت می‌کنیم.\n",
        "<p>\n",
        "در تابع remove_doc، ابتدا متن را پردازش می‌کنیم. سپس به ازای هر term ای بررسی می‌کنیم که ۱) آن term در لغت‌نامه‌مان بوده‌است و ۲) در دیکشنری مربوط به term، شماره‌ی سندی که می‌خواهیم آن را حذف کنیم وجود دارد. \n",
        "<p>\n",
        "اگر هرکدام از شرط‌های بالا برقرار نبود، exception رخ می‌دهد.در غیر این صورت دیکشنری آن term را آپدیت کرده و فرکانس کلی اش را یکی کم می‌کنیم و همچنین در لیست سند‌هایش موقعیتش در آن سند را حذف می‌کنیم.\n",
        "<p>\n",
        "در تابع get_gaps هم فاصله‌ی بین هر دو سند متوالی که یک term در آن‌ها قرار دارد را به‌دست می‌آوریم تا بعدا در فشرده‌سازی از آن استفاده کنیم.\n",
        "<p>\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "Bigram Index\n",
        "```\n",
        "</div1>\n",
        "<p>\n",
        "کلاس اصلی ما BigramIndexDictionary است که مانند بخش قبلی می‌توان برای آن نوع پیش‌پردازنده را مشخص کرد و یک لغت‌نامه نیز دارد. در لغت‌نامه به ازای هر bigram، کلمه‌ای که شامل آن است و شماره‌ی سندی که در آن قرار دارد را ذخیره می‌کنیم.\n",
        "در تابع add_new_doc ابتدا متن را پردازش می‌کنیم. پس از آن هر ترم را به صورت $term$ می‌نویسیم و به ازای هر دو حرف متوالی‌اش، در سندها جستجو می‌کنیم. همانند بخش قبل درصورتیکه آن bigram از قبل وجودداشت، دیکشنری‌اش را به‌روز می‌کنیم و اگر وجود نداشت آن را به لغت‌نامه‌مان اضافه می‌کنیم. \n",
        "<p>\n",
        "در کلاس remove_doc هم دوباره متن سندی را که می‌خواهیم حذف کنیم، پردازش می‌کنیم و برای هر term، bigramهایش را بررسی می‌کنیم. در صورتیکه در لفت‌نامه نبودند و یا در دیکشنری‌شان شماره‌ی آن سند موجود نبود، exception داده‌می‌شود. درغیراین‌صورت دیکشنری‌اش را آپدیت کرده و فرکانس را منهای یک می‌کنیم و همچنین آن سند را از بین سندهایی که بایگرم در آن قرار داشت، حذف می‌کنیم.\n",
        "<p>\n",
        "تابع get_gaps هم همانطوری که اشاره‌کردیم فاصله‌ی بین هر دو سند متوالی را که یک bigram در آن قرار دارد را به‌دست می‌آورد. (توجه داشته‌باشید که این سندها از ابتدا به ترتیب داک‌آیدی ذخیره شده‌اند.)\n",
        "<p>\n",
        "تابع get_bigrams یک term را ورودی گرفته و آرایه‌ای از تمام bigram‌هایش خروجی می‌دهد.\n",
        "<p>\n",
        "get_bigrams_count تعداد bigram‌های یک کلمه را برمی‌گرداند.\n",
        "<p>\n",
        "درنهایت تابع get_terms_with_common_bigrams که برای بخش چهارم استفاده‌می‌شود، یک کوئری را دریافت می‌کند و به ازای هر token اش bigramهای آن را محاسبه می‌کند. پس از آن به ازای هر term در کوئری‌مان بررسی می‌کند که کدام لغات موجود در لغت‌نامه بیش از یک bigram مشترک با آن term دارند. درنهایت از میان تمامی این termها آن‌هایی که دارای بیشترین تعداد bigram مشترک هستند را نگه می‌داریم. و از بین این termها آنی را انتخاب می‌کنیم که دارای کمترین edit distance باشد.\n",
        "<p>\n",
        "* توجه کنید که در این لغت‌نامه را با استفاده از همان کلاس TermVocabulary Index  که در ابتدا معرفی کرده‌بودیم، می‌سازیم. به‌طور کلی در این روش ما lemmization و stemming را انجام ندادیم تا نتایح بهتری دریافت بکنیم.\n",
        "</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJBDwr7ZSQw8"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش سوم ( فشرده سازی نمایه ها)\n",
        "</h2>\n",
        "در این بخش هدف، فشرده‌سازی نمایه‌های ساخته‌شده به دو روش \n",
        "variable code \n",
        "و\n",
        "gamma code \n",
        "است.\n",
        "\n",
        "<h3>\n",
        "نکات پیاده‌سازی \n",
        "</h3>\n",
        " هر دو روش پیاده‌سازی شود ولی برای ذخیره‌سازی نمایه‌ها در فایل و استفاده‌ از آن در بخش‌های بعد یکی از دو روش به دلخواه استفاده شود.\n",
        " <br>\n",
        "برای ذخیره نمایه در فایل می‌توانید از JSON \n",
        "یا\n",
        "pickle \n",
        "استفاده کنید.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvJQN3v8Gt__"
      },
      "source": [
        "# Compression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqvPqZwlnAmL"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h1>توضیحات</h1>\n",
        "\n",
        "برای پیاده‌سازی این بخش ابتدا در دو قسمت Variable Code و Gamme Code،  \n",
        "توابع لازم برای تبدیل id داک‌‌ها به بایت را آماده سازی می‌کنیم و سپس توابع خواندن و نوشتن را وارد می‌کنیم.\n",
        "\n",
        "\\\n",
        "از آنجایی که در هر دو روش VB و Gamma آرایه‌ای از اعداد به عنوان ورودی داده خواهد شد (آرایه gap)، توابع در این دو بخش باید بتوانند یک آرایه از اعداد را گرفته و پس از آماده‌کردن خروجی به شکل bytes، مجددا آن را به آرایه اولیه تبدیل کنند. دلیل استفاده از bytes نیز حجم کمتر آن نسبت به ذخیره‌سازی اعداد است.\n",
        "\n",
        "\\\n",
        "<h2>\n",
        "Variable Byte\n",
        "</h2>\n",
        "توابع پیاده سازی شده در این بخش عبارتند از:\n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "VB_encode_number(n)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "در روش VB Encoding، برای هر عدد مقدار خاصی تولید می‌شود. بنابراین این تابع مقدار یک عدد را به عنوان ورودی می‌گیرد (int) و مقدار خروجی آن را به صورت bytes برمی‌گرداند.\n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "ٰVB_decode_number(bytes_n)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "عملکرد این تابع معکوس تابع بالاست، یعنی با ورودی گرفتن bytes و با فرض اینکه مقدار ورودی به یک عدد اختصاص دارد، عدد مورد نظر را تولید می‌کند.\n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "VB_encode_array(list_n)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "در این تابع، آرایه‌ای از اعداد به ورودی داده می‌شود و پس از انجام VB encoding برای هر یک از اعداد به طور جداگانه، bytes های خروجی آنها در کنار هم قرار می‌گیرند تا در نهایت یک خروجی تولید شود. \n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "VB_decode_array(bytes_n)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "با ورودی دادن bytesی که نشان‌دهنده یک آرایه از اعداد است، این تابع می‌تواند آرایه اولیه را بازگرداند\n",
        "\n",
        "\n",
        "\\\n",
        "<h2>\n",
        "Gamma\n",
        "</h2>\n",
        "\n",
        "در این بخش داریم:\n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "bit_division(num)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "بر خلاف VB Encoding، در این روش مقدار نهایی تولید شده از کنار هم قرار گرفتن تمامی encodeها به‌دست می‌آید، و در پایان یک رشته باینری طولانی تولید می‌شود که امکان تبدیل مستقیم آن به bytes وجود ندارد. برای رفع این محدودیت، این تابع رشته باینری را به عنوان ورودی دریافت کرده و آن را ۸ بیت به ۸ بیت از سمت راست جدا می‌کند و اعداد تولید شده را در یک آرایه قرار داده و خروجی می‌دهد (تبدیل آرایه اعداد به bytes فرایندی بسیار ساده‌تر نسبت به بقیه تبدیل‌ها دارد). \n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "Gamma_encode(gap_ids)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "این تابع آرایه‌ای از اعداد را در ورودی دریافت می‌کند و رشته باینری مورد نیاز (Gamma_string) را تولید می‌کند. بعد از آماده شدن این رشته، از تابع قبلی استفاده می‌شود تا در نهایت خروجی bytes آماده باشد.\n",
        "\n",
        " از آنجایی که در هنگام decode کردن مقادیر گاما، اعداد ۰ و ۱ موجب ایجاد اختلال می‌شوند، تمامی مقادیر ورودی در این تابع ابتدا با ۲ جمع شده و سپس encode می‌شوند. این کار عملیات decode را نیز آسان‌تر خواهد کرد. \n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "Gamma_decode(bytes_n)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "در نهایت در تابع دیکود، مقدار ورودی داده‌شده به صورت bytes ابتدا به رشته گاما تبدیل می‌شود و سپس عملیات decode انجام می‌گیرد.\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCCAY5H9fqhj"
      },
      "source": [
        "## Variable Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqLzMO9UAChD"
      },
      "outputs": [],
      "source": [
        "def VB_encode_number(n):\n",
        "    \"\"\"Converts a decimal number to VB code\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n : int\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    bytes(ints) : bytes\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ints = []\n",
        "    i = 0\n",
        "    while True:\n",
        "        ints.insert(0, (n % 128) + 128 * (i == 0))\n",
        "        if n < 128:\n",
        "            break\n",
        "        n = n // 128\n",
        "        i += 1\n",
        "    return bytes(ints)\n",
        "\n",
        "\n",
        "def VB_decode_number(bytes_n):\n",
        "    \"\"\"Converts VB code to decimal number\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    bytes_n : bytes\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    decoded : int\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    list_n = [n for n in bytes_n]\n",
        "    list_n[-1] -= 128\n",
        "\n",
        "    decoded = list_n[0]\n",
        "    for i in range(1, len(list_n)):\n",
        "        decoded = decoded*128 + list_n[i]\n",
        "    return decoded\n",
        "\n",
        "\n",
        "def VB_encode_array(list_n):\n",
        "    \"\"\"Converts an array of decimal numbers to bytes\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    list_n : list[int]\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    vb_code : bytes\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    vb_code = bytes(0)\n",
        "    for n in list_n:\n",
        "        vb_code += bytes(VB_encode_number(n))\n",
        "    return vb_code\n",
        "\n",
        "\n",
        "def VB_decode_array(bytes_n):\n",
        "    \"\"\"Converts a byte to an array of decimal numbers\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    list_n : bytes\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    gaps : list[int]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    gaps = []\n",
        "    vb_code = bytes(0)\n",
        "    for byte in bytes_n:\n",
        "        vb_code += bytes([byte])\n",
        "        if(byte.bit_length() == 8):\n",
        "            gaps.append(VB_decode_number(vb_code))\n",
        "            vb_code = bytes(0)\n",
        "    return(gaps)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFFpGVyOfu_Q"
      },
      "source": [
        "## Gamma Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MqOITrpcU8ef"
      },
      "outputs": [],
      "source": [
        "def bit_division(num):\n",
        "    string = str(bin(num)).replace('0b', '')\n",
        "    subs = []\n",
        "    i = len(string)\n",
        "    while i > 0:\n",
        "        subs.insert(0, int('0b'+string[(i-8) * ((i-8) > 0):i], base=0))\n",
        "        i -= 8\n",
        "    return subs\n",
        "\n",
        "\n",
        "def Gamma_encode(gap_ids):\n",
        "    \"\"\"Converts a list of decimal number to Gamma code\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    gap_ids : list\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    gamma_codes = []\n",
        "    for id in gap_ids:\n",
        "\n",
        "        # compute offset\n",
        "        binary_n = bin(id + 2)\n",
        "        offset_string = str(binary_n)[3:]\n",
        "        offset_size = len(offset_string)\n",
        "\n",
        "        # compute length\n",
        "        length = unary(offset_size)\n",
        "\n",
        "        # compute gamma code\n",
        "        gamma_string = str(length) + offset_string\n",
        "\n",
        "        gamma_codes.append(gamma_string)\n",
        "\n",
        "    gamma_codes_string = '0b'+''.join(gamma_codes)\n",
        "\n",
        "    arr = bit_division(int(gamma_codes_string, base=0))\n",
        "\n",
        "    return bytes(arr)\n",
        "\n",
        "\n",
        "def Gamma_decode(bytes_n):\n",
        "    \"\"\"Decodes a string to decimal numbers\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    string_bin : string\n",
        "\n",
        "    \"\"\"\n",
        "    string_bin = ''\n",
        "    for i in bytes_n:\n",
        "        string_bin += str(bin(i)).replace('0b',\n",
        "                                          '').zfill(8 * (string_bin != ''))\n",
        "    gaps = []\n",
        "    j = 0\n",
        "\n",
        "    while j < len(string_bin):\n",
        "        count = 0\n",
        "        while j < len(string_bin) and string_bin[j] == \"1\":\n",
        "            count += 1\n",
        "            j += 1\n",
        "        offset = \"1\" + string_bin[j+1:j+count+1]\n",
        "        offset_decimal = int(offset, 2)\n",
        "        gaps.append(offset_decimal - 2)\n",
        "        j = j + count + 1\n",
        "\n",
        "    return gaps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG46xIEyGHqB"
      },
      "source": [
        "# File Read & Write"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1gJjKf-nAmO"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h1>توضیحات</h1>\n",
        "\n",
        "در این بخش توابع لازم برای خواندن و نوشتن فایل‌ها پیاده‌سازی شده‌اند. از آنجایی که تمامی آرایه‌های gaps در هر دو روش encoding به bytes تبدیل شده بودند، امکان استفاده از json وجود نداشت و بنابراین فایل‌ها با pickle نوشته می‌شوند.\n",
        "\n",
        "\n",
        "توابع پیاده سازی شده در این بخش عبارتند از:\n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "gaps_to_docs(gaps)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "در هر دو روش فشرده‌سازی، مقادیر خوانده یا نوشته‌شده مربوط به فاصله میان داک‌ها و نه id  خود آنهاست، بنابراین این تابع پیاده‌سازی شده است تا با گرفتن آرایه gaps بتواند doc_id ها راتولید کند. \n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "switch_encode(compression_type, gaps)\n",
        "store_index(dictionary, path, compression_type)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "در بخش write به دو تابع بالا نیاز داریم. تابع اول با ورودی گرفتن نوع فشرده‌سازی، encoding لازم را برای آرایه gap خروجی می‌دهد. در تابع پایین نیز یک dictionary از تمامی کلمات پردازش شده آماده می‌شود که در آن به ازای هر کلمه، آرایه gaps آن با روش فشرده‌سازی مورد نظر تغییر یافته و به bytes تبدیل شده است. پس از آماده شدن دیکشنری کافیست که در فایل مورد نظر ذخیره‌سازی شده و حجم آن نمایش داده شود. \n",
        "\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "switch_decode(compression_type, gaps)\n",
        "load_index(dictionary, path, compression_type)\n",
        "```\n",
        "</div1>\n",
        "\n",
        "در بخش read نیز دو تابع آماده شده‌اند. تابع اول با دریافت bytes مربوط به آرایه gaps هر کلمه می‌تواند آرایه اولیه را با توجه به روش فشرده‌سازی مناسب خروجی دهد. تابع load_index نیز تمامی مقادیر خوانده شده از فایل را در دیکشنری قرار می‌دهد.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mYGaofqRZxw",
        "outputId": "a24843c5-4be0-41d8-b55f-96905a152f94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 3, 6, 10]\n"
          ]
        }
      ],
      "source": [
        "def gaps_to_docs(gaps):\n",
        "    docs = []\n",
        "    docs.append(gaps[0])\n",
        "    for i in range(len(gaps)-1):\n",
        "        docs.append(docs[i] + gaps[i+1])\n",
        "    return docs\n",
        "\n",
        "\n",
        "print(gaps_to_docs([1, 2, 3, 4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GbQKRCSGLZh"
      },
      "source": [
        "## File Write\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wZGj9Ss2GHaL"
      },
      "outputs": [],
      "source": [
        "def switch_encode(compression_type, gaps):\n",
        "    switcher = {\n",
        "        'no-compression': gaps,\n",
        "        'gamma-code': Gamma_encode(gaps),\n",
        "        'variable-byte': VB_encode_array(gaps)\n",
        "    }\n",
        "    return switcher.get(compression_type)\n",
        "\n",
        "\n",
        "def store_index(dictionary, path, compression_type):\n",
        "    \"\"\"Stores the index in a file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "        Path to store the file\n",
        "\n",
        "    compression_type : str\n",
        "        Could be one of the followings:\n",
        "        - no-compression\n",
        "        - gamma-code\n",
        "        - variable-byte\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        The size of the stored file\n",
        "    \"\"\"\n",
        "\n",
        "    data = {}\n",
        "    data['terms'] = []\n",
        "    for term, doc_ids in dictionary.get_gaps().items():\n",
        "        data['terms'].append({\n",
        "            'term': term,\n",
        "            'gaps': switch_encode(compression_type, doc_ids)\n",
        "        })\n",
        "\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(pickle.dumps(data))\n",
        "\n",
        "    return os.stat(path).st_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SyqEdE0nAmQ",
        "outputId": "bf446241-cf6f-4164-a78a-638c3683d013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file size: 175759\n",
            "file size: 171749\n",
            "file size: 202722\n",
            "file size: 173517\n",
            "file size: 173710\n",
            "file size: 185471\n"
          ]
        }
      ],
      "source": [
        "directory = base_dir\n",
        "\n",
        "print(\"file size:\", store_index(english_positional_index,\n",
        "                                f\"{directory}eng_vb.bnr\", \"variable-byte\"))\n",
        "print(\"file size:\", store_index(english_positional_index,\n",
        "                                f\"{directory}eng_gc.bnr\", \"gamma-code\"))\n",
        "print(\"file size:\", store_index(english_positional_index,\n",
        "                                f\"{directory}eng_no_cmp.bnr\", \"no-compression\"))\n",
        "print(\"file size:\", store_index(persian_positional_index,\n",
        "                                f\"{directory}per_vb.bnr\", \"variable-byte\"))\n",
        "print(\"file size:\", store_index(persian_positional_index,\n",
        "                                f\"{directory}per_gc.bnr\", \"gamma-code\"))\n",
        "print(\"file size:\", store_index(persian_positional_index,\n",
        "                                f\"{directory}per_no_cmp.bnr\", \"no-compression\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVGHxoyFGONR"
      },
      "source": [
        "## File Read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def switch_decode(compression_type, gaps):\n",
        "    switcher = {\n",
        "        'no-compression': gaps,\n",
        "        'gamma-code': Gamma_decode(gaps),\n",
        "        'variable-byte': VB_decode_array(gaps)\n",
        "    }\n",
        "    return switcher.get(compression_type)\n",
        "\n",
        "\n",
        "def load_index(path, compression_type):\n",
        "    \"\"\"Loads the index from a file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "        Path of the file to load from\n",
        "\n",
        "    compression_type : str\n",
        "        Could be one of the followings:\n",
        "        - no-compression\n",
        "        - gamma-code\n",
        "        - variable-byte\n",
        "    \"\"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        data_file = f.read()\n",
        "        data = pickle.loads(data_file)\n",
        "        for term in data['terms']:\n",
        "            term['decoded_gaps'] = switch_decode(\n",
        "                compression_type, term['gaps'])\n",
        "        return data\n",
        "\n",
        "\n",
        "print(load_index(f\"{base_dir}eng_no_cmp.bnr\", \"variable-byte\"))\n",
        "print(load_index(f\"{base_dir}eng_vb.bnr\", \"variable-byte\"))\n",
        "print(load_index(f\"{base_dir}eng_gc.bnr\", \"gamma-code\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mdCFLLySQab"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش چهارم ( اصلاح پرسمان )\n",
        "</h2>\n",
        "در صورتی که پرسمان ورودی دارای غلط املایی باشد ( لغت‌ غلط لغتی است که در لغت‌نامه موجود نیست ) لازم است که با جست‌وجوی لغت‌های احتمالی و انتخاب بهترین لغت به ادامه‌ی جست‌وجو با پرسمان اصلاح‌شده پرداخته‌شود.\n",
        "برای این‌کار لازم است ابتدا به وسیله‌ی روش bigram \n",
        "و معیار jaccard \n",
        "نزدیک‌ترین لغات به لغت با غلط املایی را پیدا کنید و سپس بهترین لغت میان آن‌ها را با استفاده از معیار \n",
        "edit distance \n",
        "بیابید.\n",
        "<h3>\n",
        "نکات پیاده‌سازی:\n",
        "</h3>\n",
        "یک تابع پیاده‌سازی شود که ورودی خام را گرفته و متن تصحیح شده‌ی آن‌را نمایش دهد. دقت کنید ورودی و خروجی هر دو رشته‌ی متنی هستند.\n",
        "</br>\n",
        "نیازی به ذخیره‌سازی و فشرده‌سازی نمایه بایگرم نیست. همچنین می‌توانید از کد آماده برای محاسبه edit distance استفاده کنید.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icsfPQUO7m0C",
        "outputId": "bf4222b8-c526-40f5-a92d-871db1ba7633"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def edit_distance(s1, s2):\n",
        "    \"\"\"Calculate edit distance between two strings s1 and s2\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    s1: str\n",
        "    s2: str\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        The edit distance\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(s1)+1\n",
        "    m = len(s2)+1\n",
        "\n",
        "    edit_distance_table = [[0 for _ in range(m)] for _ in range(n)]\n",
        "\n",
        "    for i in range(n):\n",
        "        edit_distance_table[i][0] = i\n",
        "    \n",
        "    for j in range(m):\n",
        "        edit_distance_table[0][j] = j\n",
        "\n",
        "    for i in range(1, n):\n",
        "        for j in range(1, m):\n",
        "            cost = 0 if s1[i-1] == s2[j-1] else 1\n",
        "            edit_distance_table[i][j] = min(edit_distance_table[i-1][j] + 1,\n",
        "                                            edit_distance_table[i][j-1] + 1,\n",
        "                                            edit_distance_table[i-1][j-1] + cost)\n",
        "\n",
        "    return edit_distance_table[n-1][m-1]\n",
        "    \n",
        "edit_distance('cats', 'fast')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sL3E8C-nL1yG"
      },
      "outputs": [],
      "source": [
        "def get_corrected_text(preprocessor, bigram_index, vocab, raw_text):\n",
        "    \"\"\"Corrects the query\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    bigram_index: BigramIndexDictionary\n",
        "    raw_text : str\n",
        "        Input text that could be a title or a plot\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The corrected text\n",
        "    \"\"\"\n",
        "\n",
        "    corrected_tokens = []\n",
        "\n",
        "    for query in raw_text.split():\n",
        "        dprint(\"query\", query)\n",
        "        if vocab.exist(query):\n",
        "            corrected_tokens.append(query)\n",
        "            continue\n",
        "\n",
        "        # processed_query = preprocessor.prepare_text(query) \n",
        "        processed_query = query\n",
        "        dprint(\"processed_query\", processed_query)\n",
        "\n",
        "        # get terms and number of common bigrams with most common bigrams\n",
        "        terms_and_common_bigrams_count = bigram_index.get_terms_with_common_bigrams(\n",
        "          processed_query, \n",
        "          minimum_common_bigrams = 3)\n",
        "        dprint(\"terms_and_common_bigrams_count\", terms_and_common_bigrams_count)\n",
        "\n",
        "        # calculate jacard\n",
        "        max_jaccard = 0\n",
        "        suggested_words = [query]\n",
        "        for term, count in terms_and_common_bigrams_count.items():\n",
        "            jaccard = count / (bigram_index.get_bigrams_count(processed_query) + \n",
        "                           bigram_index.get_bigrams_count(term) - count)\n",
        "            dprint(\"query term jaccard\", query, term, jaccard)\n",
        "\n",
        "            if jaccard == max_jaccard:\n",
        "                suggested_words.append(term)\n",
        "            elif jaccard > max_jaccard:\n",
        "                max_jaccard = jaccard\n",
        "                suggested_words = [term]\n",
        "\n",
        "        dprint(\"suggested_words:\", suggested_words)\n",
        "\n",
        "        # get word with minimum edit distance with query\n",
        "        min_edit_distance = 1e31\n",
        "        corrected_query = query\n",
        "        for word in suggested_words:\n",
        "            edit_dis = edit_distance(word, processed_query)\n",
        "            if edit_dis < min_edit_distance:\n",
        "                min_edit_distance = edit_dis\n",
        "                corrected_query = word\n",
        "\n",
        "        corrected_tokens.append(corrected_query)\n",
        "\n",
        "    return ' '.join(corrected_tokens)\n",
        "\n",
        "def get_corrected_text_english(text):\n",
        "    return get_corrected_text(english_preprocessor, english_bigram_index, english_vocab, text)\n",
        "\n",
        "def get_corrected_text_persian(text):\n",
        "    return get_corrected_text(persian_preprocessor, persian_bigram_index, persian_vocab, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnEGLS_OnAmU"
      },
      "outputs": [],
      "source": [
        "get_corrected_text_english(\"the adevntures of herlock holmes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JGiE_yVnAmV"
      },
      "outputs": [],
      "source": [
        "get_corrected_text_persian(\"ما از جگلل به ایرنن رفتیم\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGAw1jaYDOZH"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "توضیحات بخش چهارم\n",
        "</h2>\n",
        "<p>\n",
        "در این بخش چهار تابع زده‌شده‌است که در ادامه آن‌ها را معرفی می‌کنیم.\n",
        "<p>\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "edit_distance\n",
        "```\n",
        "</div1>\n",
        "<p>\n",
        "این تابع دو رشته را ورودی گرفته و edit distance ان‌ها را محاسبه می‌کند. فرمول محاسبه‌ی edit distance در اسلایدهای درس نوشته‌شده‌است.\n",
        "<p>\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "get_corrected_text\n",
        "```\n",
        "</div1>\n",
        "<p>\n",
        "در این تابع ابتدا کوئری را tokenize می‌کنیم. پس از آن به ازای هر token چک می‌کنیم که اگر آن token در لغت‌نامه‌مان قرار داشت خودش را به فرم تصحیح‌شده‌ی کوئری اضافه می‌کنیم. (این لغت‌نامه در بخش دوم و از طریق کلاس TermVocabulary ساخته‌شد که مفصل به آن پرداختیم.)\n",
        "درغیر این صورت آن token را پردازش کرده (بدون lemmization و stemming)  و تابع get_terms_with_common_bigrams را که در بخش دوم معرفی کرده‌بودیم را صدا می‌زند. همانطور که گفتیم این تابع کلماتی از لغت‌نامه را که دارای حداقل یک bigram مشترک با tokenما هستند را برمی‌گرداند. حال در بین این کلماتی که برگردانده شدند آنهایی که jacard بیشتری دارند را در این تابع محاسبه می‌کنیم و نگه می‌داریم. در نهایت از بین کلمات باقی نیز آنی که دارای کمترین edit distance است را انتخاب می‌کنیم و با tokenمان جایگزین می‌کنیم.\n",
        "<p>\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "get_corrected_text_english\n",
        "```\n",
        "</div1>\n",
        "<p>\n",
        "این تابع متن انگلیسی را دریافت کرده و آن را به همراه پیش‌پردازنده‌ی متن انگلیسی و لغت‌نامه‌ی انگلیسی‌مان و همچنین دیکشنری‌ای که از bigramها به همراه سندهایشان داشتیم، به تابع get_corrected_text می‌دهد.\n",
        "<p>\n",
        "<div1 dir=\"ltr\">\n",
        "\n",
        "```\n",
        "get_corrected_text_persian\n",
        "```\n",
        "</div1>\n",
        "<p>\n",
        "این تابع همانند تابع بالایی است با این تفاوت که برای زبان فارسی استفاده شده‌است.\n",
        "</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epLKVSVaSPxN"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش پنجم ( نکات و جمع بندی پایانی )\n",
        "</h2>\n",
        "<ol>\n",
        "<li>\n",
        "گزارشی از پیاده سازی هر بخش تهیه در پایان هر بخش در همین فایل ژوپیتر قرار دهید.\n",
        "</li>\n",
        "<li>\n",
        "تنها زبان برنامه نویسی مجاز پایتون می باشد\n",
        "</li>\n",
        "<li>\n",
        "کد ها و توابع از نظر شباهت بررسی خواهد شد و با موارد مشابه و تقلب طبق آیین نامه تمارین درسی برخورد خواهد شد.\n",
        "</li>\n",
        "<li>\n",
        "فایل نوت بوک را زیپ کنید و با فرمت StudentNumber_phase1 ارسال نمایید.\n",
        "</li>\n",
        "<li>\n",
        "سیستم را بهینه پیاده سازی کنید تا در زمان کمتری بارگزاری و نمایه سازی شود.\n",
        "</li>\n",
        "<li>\n",
        "به ۵ پیاده سازی برتر نمره امتیازی تعلق میگیرد.\n",
        "</li>\n",
        "</ol>\n",
        "<p>\n",
        "\n",
        "در انجام پروژه اگر سوالی داشتید می توانید با ایمیل\n",
        " sinakazemi1998@gmail.com \n",
        " و\n",
        " parsa.eskandar@gmail.com\n",
        " در ارتباط باشید.\n",
        "</p>\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
